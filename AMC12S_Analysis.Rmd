---
title: "AMC12S"
author: "BYDavis"
date: "2024-04-17"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Markdown file to analyze AMC water eDNA samples, sequenced on the Stoeckle 12S primer


# Step 0: Set up files
```{r config, echo = FALSE}
# Config file with paths and versioning
source("AMC12S_config.R")
```
```{r reload, echo = FALST}
# Reload file with paths to previous outputs
source("AMC12S_reload.R")
```


# Step 1: DADA2 Workflow

## Set raw file types
```{r raw_isolate, echo = FALSE}
# Specify file name formats
fns12F <- list.files(path_raw12F)
fastqs12F <- fns12F[grepl('.gz$', fns12F)]

fns12R <- list.files(path_raw12R)
fastqs12R <- fns12R[grepl('.gz$', fns12R)]


# The file paths still include the desktop.ini file, so let's specify a file path to lead future code only to the fastq files in the folder
fns12Fisolate <- file.path(path_raw12F, fastqs12F)
fns12Risolate <- file.path(path_raw12R, fastqs12R)


# Set sample names to a vector, emove path and the .gz extension
names12Ffast <- tools::file_path_sans_ext(basename(fastqs12F))

# Repeat file_path_sans_ext to also remove the .fastq
names12F <- tools::file_path_sans_ext(names12Ffast)

names12Rfast <- tools::file_path_sans_ext(basename(fastqs12R))
names12R <- tools::file_path_sans_ext(names12Rfast)
```


## Check Sequence Quality
Run 4 randomly selected quality profile plots per primer per read type (forward or reverse). Number will correspond to the file order. 

```{r random_selection, echo = FALSE}
# Numbers for 12S Forward reads:
sample(1:78, 6, replace = FALSE)
  # Results on 3/20/2024: 75 15 63 34 35 28

# Numbers for 12S Reverse reads:
sample(1:78, 6, replace = FALSE)
  # Results on 3/20/2024: 70 40 69 38  5 10
```

Run plots

```{r quality_plots, echo = FALSE}
# 12S Forward:
ggsave("12ForwardQuality_RNG75.png", path = path_outputs, plot = plotQualityProfile(fns12Fisolate[75]), width = 6, height = 4, units = "in")

ggsave("12ForwardQuality_RNG15.png", plot = plotQualityProfile(fns12Fisolate[15]), path = path_outputs, width = 6, height = 4, units = "in")

ggsave("12ForwardQuality_RNG63.png", plot = plotQualityProfile(fns12Fisolate[63]), path = path_outputs, width = 6, height = 4, units = "in")

ggsave("12ForwardQuality_RNG34.png", plot = plotQualityProfile(fns12Fisolate[34]), path = path_outputs, width = 6, height = 4, units = "in")

ggsave("12ForwardQuality_RNG35.png", plot = plotQualityProfile(fns12Fisolate[35]), path = path_outputs, width = 6, height = 4, units = "in")

ggsave("12ForwardQuality_RNG28.png", plot = plotQualityProfile(fns12Fisolate[28]), path = path_outputs, width = 6, height = 4, units = "in")

# Notify when done
beep(sound = "fanfare")

# 12S Reverse:
ggsave("12ReverseQuality_RNG70.png", plot = plotQualityProfile(fns12Risolate[70]), path = path_outputs, width = 6, height = 4, units = "in")

ggsave("12ReverseQuality_RNG40.png", plot = plotQualityProfile(fns12Risolate[40]), path = path_outputs, width = 6, height = 4, units = "in")

ggsave("12ReverseQuality_RNG69.png", plot = plotQualityProfile(fns12Risolate[69]), path = path_outputs, width = 6, height = 4, units = "in")

ggsave("12ReverseQuality_RNG38.png", plot = plotQualityProfile(fns12Risolate[38]), path = path_outputs, width = 6, height = 4, units = "in")

ggsave("12ReverseQuality_RNG5.png", plot = plotQualityProfile(fns12Risolate[5]), path = path_outputs, width = 6, height = 4, units = "in")

ggsave("12ReverseQuality_RNG10.png", plot = plotQualityProfile(fns12Risolate[10]), path = path_outputs, width = 6, height = 4, units = "in")

# Notify when fully done
beep(sound = "fanfare")
```


The indexes and adapters have been removed from the sequence files, but the original primers are still attached. Need to account for their presence in the trim amounts and remove them.

12S MiFish region: ~170 (average length of 170, as measured by source paper)

12S Forward primer: 21 - GTCGGTAAAACTCGTGCCAGC

12S Reverse primer: 27 - CATAGTGGGGTATCTAATCCCAGTTTG


Quality notes:

12 Forward: cut after 220

12 Reverse: cut after 220


## Begin filtering process
First set the file format and names for the filtered samples

```{r filterlocale, echo = FALSE}
filt12F <- file.path(path_filt12F, "filtered", paste0(names12F, "_F_filt.fastq.gz"))
filt12R <- file.path(path_filt12R, "filtered", paste0(names12R, "_R_filt.fastq.gz"))
```

Filter according to the quality note + primer length parameters 
```{r filtTrim, echo = TRUE}
# Trimming parameters
filtout12sync <- filterAndTrim(file.path(path_raw12F, fastqs12F), file.path(path_filt12F, paste0(names12F, "filt.fastq.gz")), file.path(path_raw12R, fastqs12R), file.path(path_filt12R, paste0(names12R, "filt.fastq.gz")), trimLeft = c(21,27), trimRight=c(80), maxN=0, maxEE=c(2,2), verbose=TRUE) 

# Notify when done
beep(sound = "fanfare")
```
AMC23_C721_MR2 and MR1 removed


## Explore filtered output 
Can look at the dimensions of each RDS output, and order by the filtered read amount, and/or look at the number of total raw reads compared to the filtered out reads

```{r assess_filt, echo = FALSE}
dim(filtout12sync)

# Order by filtered read amount
filtout12sync[order(filtout12sync[,2], decreasing=FALSE),]

# Compare total raw in and filtered out read amounts
colSums(filtout12sync)

# Save output
write.csv(filtout12sync, file.path(path_outputs, "FiltoutputTable.csv"))
```


```{r filter_trends, echo = FALSE}

# Make plot
filttrend12sync <- ggplot(as.data.frame(filtout12sync)) + geom_point(aes(row.names(filtout12sync), reads.in), color = "blue") + geom_point(aes(row.names(filtout12sync), reads.out), color = "orange") + ggtitle("Filter Trends for AMC 12 Synced Forward Reads")

# View plot
filttrend12sync

# Save
ggsave("FilterTrends_12Sync.png", plot = filttrend12sync, path = path_outputs, width = 6, height = 4, units = "in")
```


## Error Rates and Dereplication

First we need to set a seed and make sure the paths are all still set.

```{r error_setup, echo = FALSE}
set.seed(9450)

# Set the names for the filtered files we'll be using

# create a list of files in the path
filtnames12Finter <- list.files(path_filt12F, full.names = TRUE)

# Specify I only want the files with the .gz extension
filtnames12F <- filtnames12Finter[grepl('.gz$', filtnames12Finter)]

# Extract just the file name, not the path, and remove the .gz extension. This leaves on the .fastq extension
fastqfilt12F <- tools::file_path_sans_ext(basename(filtnames12F))

# Remove the .fastq extension
names12Ffilt <- tools::file_path_sans_ext(basename(fastqfilt12F))

# 12Reverse
filtnames12Rinter <- list.files(path_filt12R, full.names = TRUE)
filtnames12R <- filtnames12Rinter[grepl('.gz$', filtnames12Rinter)]
fastqfilt12R <- tools::file_path_sans_ext(basename(filtnames12R))
names12Rfilt <- tools::file_path_sans_ext(basename(fastqfilt12R))
```


## Dereplication

This step comes from the dada2 workflow (https://bioconductor.org/packages/devel/bioc/vignettes/dada2/inst/doc/dada2-intro.html#learn-the-error-rates)

```{r derep, echo = FALSE}
derep12F <- derepFastq(filtnames12F, verbose=TRUE)
derep12R <- derepFastq(filtnames12R, verbose=TRUE)
```

Now that the names are set up, we can run the simulations to learn and estimate the number of errors in each filtered folder. This step is in Sue's code (and is the source of the saveRDS and plotErrors lines), but using the default parameters from the dada2 workflow


## Error Rates
```{r error_rates, echo = FALSE}
# Forward error rates
err12F <- learnErrors(derep12F, multithread = FALSE, randomize = TRUE)

# Save object
saveRDS(err12F, "G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/12S/6-Jun03-2024/12Forward_Error.rds")

# Generate and save error plot
ggsave("12Forward_ErrorPlot.png", path = path_outputs, plotErrors(err12F, nominalQ = TRUE), width = 6, height = 4, units = "in") 


# Reverse error rates
err12R <- learnErrors(derep12R, multithread = FALSE, randomize = TRUE)

# Save object
saveRDS(err12R, "G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/12S/6-Jun03-2024/12Reverse_Error.rds")

# Generate and save error plot
ggsave("12Reverse_ErrorPlot.png", path = path_outputs, plotErrors(err12R, nominalQ = TRUE), width = 6, height = 4, units = "in") 

# This takes a long time. If you have to do it again, include this:
beep(sound = "fanfare")
```


## Infer sample composition
```{r sample_composition, echo = FALSE}
# Sample composition for forward
dada12F <- dada(derep12F, err = err12F, multithread = FALSE)

# Notification
beep(sound = "coin")


# Sample composition for reverse
dada12R <- dada(derep12R, err = err12R, multithread = FALSE)

# Notification
beep(sound = "fanfare")

# Save all in case I need to reload the dada objects
saveRDS(dada12F, "G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/12S/6-Jun03-2024/12Forward_SampleComp.rds")
saveRDS(dada12R, "G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/12S/6-Jun03-2024/12Reverse_SampleComp.rds")
```


Merge paired reads
```{r merge_reads, echo = FALSE}
mergers12 <- mergePairs(dada12F, path_filt12F, dada12R, path_filt12R, verbose=TRUE)

# Turn into a sequence table
seqtab <- makeSequenceTable(mergers12)

# save
saveRDS(seqtab, "G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/12S/6-Jun03-2024/12MergedSampleComp.rds")
```


## Remove Chimeras
```{r no_chim, echo = FALSE}
# Remove chimeras
seqtab12.nochim <- removeBimeraDenovo(seqtab, method = "consensus", multithread = FALSE, verbose = TRUE)

# Save output
saveRDS(seqtab12.nochim, "G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/12S/6-Jun03-2024/12Merged Sequence No Chimera Table.rds")

# Notification
beep(sound = "coin")
```


## Workflow Verification
Since some samples were dropped during filter and trim, the number of rows between the filter output and the rest of the workflow is different. We can still make a table of the post-filter read numbers to compare with the filtoutput table
```{r workflow_verification, echo = FALSE}
# Set function
getN <- function(x) sum(getUniques(x))

# Combine read numbers
track12 <- cbind(sapply(dada12F, getN), sapply(dada12R, getN), sapply(mergers12, getN), rowSums(seqtab12.nochim))

# Set column names
colnames(track12) <- c( "denoisedF", "denoisedR", "merged", "nonchim")

# Save the results of the workflow verification
write.csv(track12, file.path(path_outputs, "12S_WorkflowVerification.csv"))
```


## Assign Taxonomy
```{r assign_taxonomy, echo = FALSE}
# Very slow and intensive
all.taxa <- assignTaxonomy(seqtab12.nochim, 'C:/Users/bydav/Desktop/RefDB_Dev/output/2-May17-2024/12S_REFDB.fasta', tryRC = TRUE, verbose = TRUE)

# Notify when done
beep(sound = "fanfare")

# Save output
write.csv(all.taxa, file.path(path_outputs, "12SAMC_AssignedTaxa.csv"))
```


# Step 2: Transfer to Phyloseq
### NTS: Will need to repeat this (or figure out how to otherwise add metadata) once the meta sheet is complete

First we need to update the row names for the seqtab12.nochim, all.taxa, and meta objects before attempting to make the phyloseq object. Since at least one sample was dropped during processing, we have to read meta in without row.names, remove the row(s) associated with the dropped sample(s), then reset the sampleID column to row.names
```{r name_check, include = FALSE}
# Update the all.taxa row names to be the actual sequences
all.taxa <- data.frame(all.taxa, row.names = 1)

# Order seqtab12.nochim by row names
seqtab12.nochim <- seqtab12.nochim[order(row.names(seqtab12.nochim)), ]

# Remove the row(s) associated with dropped sample(s) from the meta spreadsheet
meta <- subset(meta, sample != "AMC23_C721") 
# Set the sample column as row.names
meta <- data.frame(meta, row.names = 1)
# Order the meta file by row.names
meta <- meta[order(row.names(meta)), ]

# Make sure all samples in seqtab.nochim match and are in the same order as in meta, because the next step is a flat replacement of row.names
row.names(seqtab12.nochim) <- row.names(meta)
```


## Create the Phyloseq object
```{r ps_object, echo = FALSE}
# Create phyloseq object with all samples
EX_ps <- phyloseq(otu_table(seqtab12.nochim, taxa_are_rows=FALSE), sample_data(meta), tax_table(as.matrix(all.taxa)))

# SAVE 
saveRDS(EX_ps, "G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/12S/6-Jun03-2024/InitialPhyloseq.rds")
```


## Exploratory richness plots
```{r initial_exploratory}
# I'd like to make a stacked bar plot, before any taxa-filtering, of the read abundances
# Set function to make a proportional graph
EX_ps.func <- transform_sample_counts(EX_ps, function(x) x / sum(x) )
# Plot based on Phylum
plot_bar(EX_ps.func, fill="Phylum") + ggtitle("Proportion by Phylum of Identified Reads - 12S")
  # Warning: Removed 1076 rows containing missing values or values outside the scale range (`geom_bar()`). 

# Save plot
ggsave("PreDecontam_IDProportions.png", path = path_outputs, plot_bar(EX_ps.func, fill="Phylum") + ggtitle("Proportion by Phylum of Identified Reads"), width = 7, height = 4, units = "in") 
```


# Step 3: Decontam - From PNW

## Inspect Library Sizes
```{r library_size, echo = FALSE}
df <- as.data.frame(sample_data(EX_ps)) # Put sample_data into a ggplot-friendly data.frame
df$LibrarySize <- sample_sums(EX_ps)
df <- df[order(df$LibrarySize),]
df$Index <- seq(nrow(df))
ggplot(data=df, aes(x=Index, y=LibrarySize, color=Type)) + geom_point()

ggsave("DecontamLibrarySize_Type.png", path = path_outputs, ggplot(data=df, aes(x=Index, y=LibrarySize, color=Type)) + geom_point() + ggtitle("12S Identified Read Numbers per Sample, by Sample Type"), width = 6, height = 4, units = "in") 

```
Controls are generally higher than eDNA, with some 0s

Check order by year too
```{r library_size, echo = FALSE}
df <- as.data.frame(sample_data(EX_ps)) # Put sample_data into a ggplot-friendly data.frame
df$LibrarySize <- sample_sums(EX_ps)
df <- df[order(df$LibrarySize),]
df$Index <- seq(nrow(df))
ggplot(data=df, aes(x=Index, y=LibrarySize, color=Year)) + geom_point()

ggsave("DecontamLibrarySize_Year.png", path = path_outputs, ggplot(data=df, aes(x=Index, y=LibrarySize, color=Year)) + geom_point() + ggtitle("12S Identified Read Numbers per Sample, by Collection Year"), width = 6, height = 4, units = "in") 
```
Unsure why it's making a gradient - figure out later, but 2022 surprisingly seems to have more reads than 2023 - will see if that persists after decontam


## Remove Contaminants

The standard decontam package uses either frequency or prevalence to identify and remove contaminants, but relies on blanks being true negative controls to use presence/absence of reads between true and negative samples to identify contaminants. Since these blank samples do have a significant number of reads, I use the Ishaq decontam method instead - isolating reads that were identified in the controls and removing them from all samples, based on which samples were extracted with which blank.


```{r decontam_isolate, echo = FALSE}
# subset each DNA extraction batch
batch1 = subset_samples(EX_ps, Ebatch == "1")  
batch2 = subset_samples(EX_ps, Ebatch == "2")
batch3 = subset_samples(EX_ps, Ebatch == "3")  
batch4 = subset_samples(EX_ps, Ebatch == "4")  
batch5 = subset_samples(EX_ps, Ebatch == "5")  
batch6 = subset_samples(EX_ps, Ebatch == "6")  
batch7 = subset_samples(EX_ps, Ebatch == "7")  
batch8 = subset_samples(EX_ps, Ebatch == "8")  
batch9 = subset_samples(EX_ps, Ebatch == "9")  
batch10 = subset_samples(EX_ps, Ebatch == "10")  


# subset controls and prune to only those taxa
batch1_sub = subset_samples(batch1, Type == "NegCon")
batch2_sub = subset_samples(batch2, Type == "NegCon")
batch3_sub = subset_samples(batch3, Type == "NegCon")
batch4_sub = subset_samples(batch4, Type == "NegCon")
batch5_sub = subset_samples(batch5, Type == "NegCon")
batch6_sub = subset_samples(batch6, Type == "NegCon")
batch7_sub = subset_samples(batch7, Type == "NegCon")
batch8_sub = subset_samples(batch8, Type == "NegCon")
batch9_sub = subset_samples(batch9, Type == "NegCon")
batch10_sub = subset_samples(batch10, Type == "NegCon")


batch1_sub <- prune_taxa(taxa_sums(batch1_sub) > 0, batch1_sub)
batch2_sub <- prune_taxa(taxa_sums(batch2_sub) > 0, batch2_sub)
batch3_sub <- prune_taxa(taxa_sums(batch3_sub) > 0, batch3_sub)
batch4_sub <- prune_taxa(taxa_sums(batch4_sub) > 0, batch4_sub)
batch5_sub <- prune_taxa(taxa_sums(batch5_sub) > 0, batch5_sub)
batch6_sub <- prune_taxa(taxa_sums(batch6_sub) > 0, batch6_sub)
batch7_sub <- prune_taxa(taxa_sums(batch7_sub) > 0, batch7_sub)
batch8_sub <- prune_taxa(taxa_sums(batch8_sub) > 0, batch8_sub)
batch9_sub <- prune_taxa(taxa_sums(batch9_sub) > 0, batch9_sub)
batch10_sub <- prune_taxa(taxa_sums(batch10_sub) > 0, batch10_sub)


# Make the taxa names into a vector so you can remove them, then use the keep vector for the prune taxa argument, because it wants the argument to be true (matching), and repeat for both batches
batch1_ctrl <- as.vector(taxa_names(batch1_sub)) 
batch1_vec <- as.vector(taxa_names(batch1)) 
batch1_kp <- setdiff(batch1_vec, batch1_ctrl)
batch1_clean <- prune_taxa(batch1_kp, batch1)

batch2_ctrl <- as.vector(taxa_names(batch2_sub)) 
batch2_vec <- as.vector(taxa_names(batch2)) 
batch2_kp <- setdiff(batch2_vec, batch2_ctrl)
batch2_clean <- prune_taxa(batch2_kp, batch2)

batch3_ctrl <- as.vector(taxa_names(batch3_sub)) 
batch3_vec <- as.vector(taxa_names(batch3)) 
batch3_kp <- setdiff(batch3_vec, batch3_ctrl)
batch3_clean <- prune_taxa(batch3_kp, batch3)

batch4_ctrl <- as.vector(taxa_names(batch4_sub)) 
batch4_vec <- as.vector(taxa_names(batch4)) 
batch4_kp <- setdiff(batch4_vec, batch4_ctrl)
batch4_clean <- prune_taxa(batch4_kp, batch4)

batch5_ctrl <- as.vector(taxa_names(batch5_sub)) 
batch5_vec <- as.vector(taxa_names(batch5)) 
batch5_kp <- setdiff(batch5_vec, batch5_ctrl)
batch5_clean <- prune_taxa(batch5_kp, batch5)

batch6_ctrl <- as.vector(taxa_names(batch6_sub)) 
batch6_vec <- as.vector(taxa_names(batch6)) 
batch6_kp <- setdiff(batch6_vec, batch6_ctrl)
batch6_clean <- prune_taxa(batch6_kp, batch6)

batch7_ctrl <- as.vector(taxa_names(batch7_sub)) 
batch7_vec <- as.vector(taxa_names(batch7)) 
batch7_kp <- setdiff(batch7_vec, batch7_ctrl)
batch7_clean <- prune_taxa(batch7_kp, batch7)

batch8_ctrl <- as.vector(taxa_names(batch8_sub)) 
batch8_vec <- as.vector(taxa_names(batch8)) 
batch8_kp <- setdiff(batch8_vec, batch8_ctrl)
batch8_clean <- prune_taxa(batch8_kp, batch8)

batch9_ctrl <- as.vector(taxa_names(batch9_sub)) 
batch9_vec <- as.vector(taxa_names(batch9)) 
batch9_kp <- setdiff(batch9_vec, batch9_ctrl)
batch9_clean <- prune_taxa(batch9_kp, batch9)

batch10_ctrl <- as.vector(taxa_names(batch10_sub)) 
batch10_vec <- as.vector(taxa_names(batch10)) 
batch10_kp <- setdiff(batch10_vec, batch10_ctrl)
batch10_clean <- prune_taxa(batch10_kp, batch10)

# Save the phyloseq object of identified contaminants
pstrimmed <- merge_phyloseq(batch1_sub, batch2_sub, batch3_sub, batch4_sub, batch5_sub, batch6_sub, batch7_sub, batch8_sub, batch9_sub, batch10_sub) 
saveRDS(pstrimmed, "G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/12S/6-Jun03-2024/DecontamRemoved.rds")

```

```{r}
# Merge the phyloseq objects back together, then remove any blank taxa or samples
ps_clean <- merge_phyloseq(batch1_clean, batch2_clean, batch3_clean, batch4_clean, batch5_clean, batch6_clean, batch7_clean, batch8_clean, batch9_clean, batch10_clean) 

# Clean out taxa/SV columns that are no longer present
ps_clean <- prune_taxa(taxa_sums(ps_clean) > 0, ps_clean) 
ps_clean <- prune_samples(sample_sums(ps_clean) > 0, ps_clean)

ps_clean
ps_clean.stack <- transform_sample_counts(ps_clean, function(x) x / sum(x) )
# Plot based on Phylum
plot_bar(ps_clean.stack, fill="Kingdom") + ggtitle("Proportion by Kingdom of Identified Reads - COI")
```
phyloseq-class experiment-level object
otu_table()   OTU Table:         [ 508 taxa and 58 samples ]
sample_data() Sample Data:       [ 58 samples by 15 sample variables ]
tax_table()   Taxonomy Table:    [ 508 taxa by 6 taxonomic ranks ]

I still want to remove bacterial and plant/algae identifications, so don't save the object yet

```{r remove_taxa, echo = FALSE}
# Remove plant and others
ps12S <- ps_clean %>% 
  subset_taxa(Kingdom != "Bacillota") 
ps12S <- ps12S %>% 
  subset_taxa(Kingdom != "Chlorophyta")
ps12S <- ps12S %>% 
  subset_taxa(Kingdom != "Cyanobacteriota")
ps12S <- ps12S %>% 
  subset_taxa(Kingdom != "Pseudomonadota")
ps12S <- ps12S %>% 
  subset_taxa(Kingdom != "Foraminifera")
ps12S <- ps12S %>% 
  subset_taxa(Kingdom != "Streptophyta")
```

```{r clean_columns, echo = FALSE}
ps12S <- prune_taxa(taxa_sums(ps12S) > 0, ps12S) 
ps12S <- prune_samples(sample_sums(ps12S) > 0, ps12S)

ps12S.stack <- transform_sample_counts(ps12S, function(x) x / sum(x) )
# Plot based on Class
plot_bar(ps12S.stack, fill="Class") + ggtitle("Proportion of Cleaned Reads by Class.png")

ps12S

ggsave("CleanedClassIDs.png", path = path_outputs, plot_bar(ps12S.stack, fill="Class") + ggtitle("Proportion of Cleaned Reads by Class.png") + ggtitle("12S Identified Clean Reads"), width = 8, height = 5, units = "in") 

saveRDS(ps12S, "G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/12S/6-Jun03-2024/CleanPhyloseq.RDS")
```
phyloseq-class experiment-level object
otu_table()   OTU Table:         [ 136 taxa and 55 samples ]
sample_data() Sample Data:       [ 55 samples by 15 sample variables ]
tax_table()   Taxonomy Table:    [ 136 taxa by 6 taxonomic ranks ]

### All clean prior

# Step 4: Alpha Diversity Analysis

## Rarefaction
```{r rarecurve, echo = FALSE}
rc <-as.data.frame(otu_table(ps12S))
test <- rarecurve(rc, step = 10, cex=0.5, label = FALSE)

raremax <- max(rowSums(otu_table(ps12S))) # Max SV number is 74165
raremin <- min(rowSums(otu_table(ps12S))) # Min SV number is 7
rowSums(otu_table(ps12S))
```


## Chao Alpha Diversity