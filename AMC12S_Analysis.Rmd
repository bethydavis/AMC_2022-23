---
title: "AMC12S"
author: "BYDavis"
date: "2024-04-17"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Markdown file to analyze AMC water eDNA samples, using Dr. Sue Ishaq's DNA Sequencing Analysis workflow (to start). 12S Analysis only

Debugging statements are preceded with ###

Prior to this Rmd, the raw fastq files have been renamed in the repo UM_FSM_Cleaning


# Set up packages and paths with config file
```{r 12S_config}
source("AMC12S_config.R")
```

# Set folder paths and file types
```{r raw_paths, echo = FALSE}
# Specify file name formats
fns12F <- list.files(path_raw12F)
fastqs12F <- fns12F[grepl('.gz$', fns12F)]

fns12R <- list.files(path_raw12R)
fastqs12R <- fns12R[grepl('.gz$', fns12R)]


# The file paths still include the desktop.ini file, so let's specify a file path to lead future code only to the fastq files in the folder
fns12Fisolate <- file.path(path_raw12F, fastqs12F)
fns12Risolate <- file.path(path_raw12R, fastqs12R)


# Set sample names to a vector, emove path and the .gz extension
names12Ffast <- tools::file_path_sans_ext(basename(fastqs12F))

# Repeat file_path_sans_ext to also remove the .fastq
names12F <- tools::file_path_sans_ext(names12Ffast)

names12Rfast <- tools::file_path_sans_ext(basename(fastqs12R))
names12R <- tools::file_path_sans_ext(names12Rfast)
```


# Check Sequence Quality
Run 4 randomly selected quality profile plots per primer per read type (forward or reverse). Number will correspond to the file order. Min is set to 2 to avoid the desktop.ini file that GoogleDrive desktop creates from being chosen

```{r random_selection}
# Numbers for 12S Forward reads:
sample(1:78, 6, replace = FALSE)
  # Results on 3/20/2024: 75 15 63 34 35 28

# Numbers for 12S Reverse reads:
sample(1:78, 6, replace = FALSE)
  # Results on 3/20/2024: 70 40 69 38  5 10
```

Note: plots for the 3/20 RNG quality profiles were re-run on 4/17 to standardize plot dimensions
```{r qualityplotgeneration}
# 12S Forward:
ggsave("12ForwardQuality_RNG75.png", path = path_outputs, plot = plotQualityProfile(fns12Fisolate[75]), width = 6, height = 4, units = "in")

ggsave("12ForwardQuality_RNG15.png", plot = plotQualityProfile(fns12Fisolate[15]), path = path_outputs, width = 6, height = 4, units = "in")

ggsave("12ForwardQuality_RNG63.png", plot = plotQualityProfile(fns12Fisolate[63]), path = path_outputs, width = 6, height = 4, units = "in")

ggsave("12ForwardQuality_RNG34.png", plot = plotQualityProfile(fns12Fisolate[34]), path = path_outputs, width = 6, height = 4, units = "in")

ggsave("12ForwardQuality_RNG35.png", plot = plotQualityProfile(fns12Fisolate[35]), path = path_outputs, width = 6, height = 4, units = "in")

ggsave("12ForwardQuality_RNG28.png", plot = plotQualityProfile(fns12Fisolate[28]), path = path_outputs, width = 6, height = 4, units = "in")

beep(sound = "fanfare")
```

```{r evenmorequalityplots}
# 12S Reverse:
ggsave("12ReverseQuality_RNG70.png", plot = plotQualityProfile(fns12Risolate[70]), path = path_outputs, width = 6, height = 4, units = "in")

ggsave("12ReverseQuality_RNG40.png", plot = plotQualityProfile(fns12Risolate[40]), path = path_outputs, width = 6, height = 4, units = "in")

ggsave("12ReverseQuality_RNG69.png", plot = plotQualityProfile(fns12Risolate[69]), path = path_outputs, width = 6, height = 4, units = "in")

ggsave("12ReverseQuality_RNG38.png", plot = plotQualityProfile(fns12Risolate[38]), path = path_outputs, width = 6, height = 4, units = "in")

ggsave("12ReverseQuality_RNG5.png", plot = plotQualityProfile(fns12Risolate[5]), path = path_outputs, width = 6, height = 4, units = "in")

ggsave("12ReverseQuality_RNG10.png", plot = plotQualityProfile(fns12Risolate[10]), path = path_outputs, width = 6, height = 4, units = "in")

beep(sound = "fanfare")
```


The indexes and adapters have been removed from the sequence files, but the original primers are still attached. Need to account for their presence in the trim amounts and remove them.

12S MiFish region: ~170 (average length of 170, as measured by source paper)

12S Forward primer: 21 - GTCGGTAAAACTCGTGCCAGC

12S Reverse primer: 27 - CATAGTGGGGTATCTAATCCCAGTTTG


Quality notes:

12 Forward: cut after 220

12 Reverse: cut after 220


# Begin filtering process
First set the file format and names for the filtered samples

```{r filterlocale}
filt12F <- file.path(path_filt12F, "filtered", paste0(names12F, "_F_filt.fastq.gz"))
filt12R <- file.path(path_filt12R, "filtered", paste0(names12R, "_R_filt.fastq.gz"))
```

Filter according to the quality note + primer length parameters 
```{r filt12}
filtout12sync <- filterAndTrim(file.path(path_raw12F, fastqs12F), file.path(path_filt12F, paste0(names12F, "filt.fastq.gz")), file.path(path_raw12R, fastqs12R), file.path(path_filt12R, paste0(names12R, "filt.fastq.gz")), trimLeft = c(21,27), trimRight=c(80), maxN=0, maxEE=c(2,2), verbose=TRUE) 
beep(sound = "fanfare")
```
AMC23_C721_MR2 and MR1 removed


# Explore filtered output 
Can look at the dimensions of each RDS output, and order by the filtered read amount, and/or look at the number of total raw reads compared to the filtered out reads

```{r assess filt_12F}
dim(filtout12sync)

# Order by filtered read amount
filtout12sync[order(filtout12sync[,2], decreasing=FALSE),]

# Compare total raw in and filtered out read amounts
colSums(filtout12sync)

write.csv(filtout12sync, file.path(path_outputs, "FiltoutputTable.csv"))
```

# Look at filtered trends
```{r filtertrends}
filttrend12sync <- ggplot(as.data.frame(filtout12sync)) + geom_point(aes(row.names(filtout12sync), reads.in), color = "blue") + geom_point(aes(row.names(filtout12sync), reads.out), color = "orange") + ggtitle("Filter Trends for AMC 12 Synced Forward Reads")
filttrend12sync

ggsave("FilterTrends_12Sync.png", plot = filttrend12sync, path = path_outputs, width = 6, height = 4, units = "in")
```

just out of curiosity's sake, let's also explore some quality profiles again from the filtered reads

```{r plotfiltered}
#Compare post and pre-filter and trim
plotQualityProfile("G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/Raw/12S/Read1/AMC22_MB01_MR1.fastq.gz")

plotQualityProfile("G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/Filtered/12S Forward/5-May02-2024/AMC22_MB01_MR1filt.fastq.gz")


plotQualityProfile("G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/Raw/12S/Read2/AMC22_MB01_MR2.fastq.gz")

plotQualityProfile("G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/Filtered/12S Reverse/5-May02-2024/AMC22_MB01_MR2filt.fastq.gz")
```

# Error Rates and Dereplication

First we need to set a seed and make sure the paths are all still set.

```{r error setup}
set.seed(9450)

# Set the names for the filtered files we'll be using

# create a list of files in the path
filtnames12Finter <- list.files(path_filt12F, full.names = TRUE)

# Specify I only want the files with the .gz extension
filtnames12F <- filtnames12Finter[grepl('.gz$', filtnames12Finter)]

# Extract just the file name, not the path, and remove the .gz extension. This leaves on the .fastq extension
fastqfilt12F <- tools::file_path_sans_ext(basename(filtnames12F))

# Remove the .fastq extension
names12Ffilt <- tools::file_path_sans_ext(basename(fastqfilt12F))

# 12Reverse
filtnames12Rinter <- list.files(path_filt12R, full.names = TRUE)
filtnames12R <- filtnames12Rinter[grepl('.gz$', filtnames12Rinter)]
fastqfilt12R <- tools::file_path_sans_ext(basename(filtnames12R))
names12Rfilt <- tools::file_path_sans_ext(basename(fastqfilt12R))
```

## Dereplication

This step comes from the dada2 workflow (https://bioconductor.org/packages/devel/bioc/vignettes/dada2/inst/doc/dada2-intro.html#learn-the-error-rates), not Sue's code

```{r derep}
derep12F <- derepFastq(filtnames12F, verbose=TRUE)
derep12R <- derepFastq(filtnames12R, verbose=TRUE)
```

Now that the names are set up, we can run the simulations to learn and estimate the number of errors in each filtered folder. This step is in Sue's code (and is the source of the saveRDS and plotErrors lines), but using the default parameters from the dada2 workflow

The default nbases is 1e8. Using this default since Sue's 1e6 parameter filled up after only one sample

## Error Rates
```{r errorrates}
# Forward error rates
err12F <- learnErrors(derep12F, multithread = FALSE, randomize = TRUE)

saveRDS(err12F, "G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/12S/6-Jun03-2024/12Forward_Error.rds")

ggsave("12Forward_ErrorPlot.png", path = path_outputs, plotErrors(err12F, nominalQ = TRUE), width = 6, height = 4, units = "in") 

# Reverse error rates
err12R <- learnErrors(derep12R, multithread = FALSE, randomize = TRUE)

saveRDS(err12R, "G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/12S/6-Jun03-2024/12Reverse_Error.rds")

ggsave("12Reverse_ErrorPlot.png", path = path_outputs, plotErrors(err12R, nominalQ = TRUE), width = 6, height = 4, units = "in") 

# This takes a long time. If you have to do it again, include this:
beep(sound = "fanfare")
```

### Load error rates back in if needed:
```{r}
err12F <- readRDS("G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/12S/5-May02-2024/12Forward_Error.rds")
err12R <- readRDS("G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/12S/5-May02-2024/12Reverse_Error.rds")
```

# Infer sample composition
```{r samplecomposition}
dada12F <- dada(derep12F, err = err12F, multithread = FALSE)
print("dada 12F finished")
beep(sound = "coin")

dada12R <- dada(derep12R, err = err12R, multithread = FALSE)
print("dada 12R finished")
beep(sound = "fanfare")

# Save all in case I need to reload the dada objects
saveRDS(dada12F, "G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/12S/6-Jun03-2024/12Forward_SampleComp.rds")
saveRDS(dada12R, "G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/12S/6-Jun03-2024/12Reverse_SampleComp.rds")
```


Merge paired reads
```{r}
mergers12 <- mergePairs(dada12F, path_filt12F, dada12R, path_filt12R, verbose=TRUE)

# Update formatting into a matrix array
seqtab <- makeSequenceTable(mergers12)

# Inspect the merger data.frame from the first sample
head(seqtab[[1]])

saveRDS(seqtab, "G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/12S/6-Jun03-2024/12MergedSampleComp.rds")

```


# Remove Chimeras
```{r nochimB}

seqtab12.nochim <- removeBimeraDenovo(seqtab, method = "consensus", multithread = FALSE, verbose = TRUE)
# Save output
saveRDS(seqtab12.nochim, "G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/12S/6-Jun03-2024/12Merged Sequence No Chimera Table.rds")

beep(sound = "coin")
```



# Workflow Verification
Reload seqtab if needed
```{r reload seqtab}
seqtab12.nochim <- readRDS("G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/12S/6-Jun03-2024/12Merged Sequence No Chimera Table.rds")
```

```{r workflow_verification, echo = FALSE}
getN <- function(x) sum(getUniques(x))

track12 <- cbind(filtout12sync, sapply(dada12F, getN), sapply(dada12R, getN), sapply(mergers12, getN), rowSums(seqtab12.nochim))

colnames(track12) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim")

# Save the results of the workflow verification
write.csv(track12, file.path(path_outputs, "12S_WorkflowVerification.csv"))
```

# Assign Taxonomy
```{r assign_taxonomy, echo = FALSE}
# Very slow and intensive
all.taxa <- assignTaxonomy(seqtab12.nochim, 'C:/Users/bydav/Desktop/RefDB_Dev/output/2-May17-2024/12S_REFDB.fasta', tryRC = TRUE, verbose = TRUE)
beep(sound = "fanfare")

write.csv(all.taxa, file.path(path_outputs, "12SAMC_AssignedTaxa.csv"))

all.taxa <- read.csv(file.path(path_outputs, "12SAMC_AssignedTaxa.csv"))
```

### NTS: Continue here 5/21
# Phyloseq

Load in a metadata file - make sure the sample names and order match between it and the seqtab
```{r name_check, include = FALSE}
rownames <- row.names(seqtab12.nochim)

regexp <- "([[:alnum:]]+_)[[:alnum:]]+"

# process string
newnames <- (str_extract(rownames, regexp))

row.names(seqtab12.nochim) <- newnames
```

# Convince R by force that they match - this is a flat replacement, not a match-up - find a better way that doesn't flat replace


```{r ps_object, echo = FALSE}
# Create phyloseq object with all samples
EX_ps <- phyloseq(otu_table(seqtab12.nochim, taxa_are_rows=FALSE), sample_data(meta), tax_table(as.matrix(all.taxa)))

#EX_ps
```


# Decontam with Negative Controls (Ishaq Method)
Clean all batches and then merge together into a clean phyloseq object - make this into a loop after MSWC
```{r}
# batch 3
fbatch3 = subset_samples(EX_ps, Fbatch == "3")  
fbatch3_kit = subset_samples(fbatch3, Type == "NegCon")
fbatch3_kit <- prune_taxa(taxa_sums(fbatch3_kit) > 0, fbatch3_kit)
fb3_control_vec <- as.vector(taxa_names(fbatch3_kit)) 
fb3_vec <- as.vector(taxa_names(fbatch3)) 
fb3_keep <- setdiff(fb3_vec, fb3_control_vec)
fb3_clean <- prune_taxa(fb3_keep, fbatch3)

# batch 4
#fbatch4 = subset_samples(EX_ps, Fbatch == "4")  
#fbatch4_kit = subset_samples(fbatch4, Type == "NegCon")
#fbatch4_kit <- prune_taxa(taxa_sums(fbatch4_kit) > 0, fbatch4_kit)
#fb4_control_vec <- as.vector(taxa_names(fbatch4_kit)) 
#fb4_vec <- as.vector(taxa_names(fbatch4)) 
#fb4_keep <- setdiff(fb4_vec, fb4_control_vec)
#fb4_clean <- prune_taxa(fb4_keep, fbatch4)

# batch 5
fbatch5 = subset_samples(EX_ps, Fbatch == "5")  
fbatch5_kit = subset_samples(fbatch5, Type == "NegCon")
fbatch5_kit <- prune_taxa(taxa_sums(fbatch5_kit) > 0, fbatch5_kit)
fb5_control_vec <- as.vector(taxa_names(fbatch5_kit)) 
fb5_vec <- as.vector(taxa_names(fbatch5)) 
fb5_keep <- setdiff(fb5_vec, fb5_control_vec)
fb5_clean <- prune_taxa(fb5_keep, fbatch5)

# batch 6
fbatch6 = subset_samples(EX_ps, Fbatch == "6")  
fbatch6_kit = subset_samples(fbatch6, Type == "NegCon")
fbatch6_kit <- prune_taxa(taxa_sums(fbatch6_kit) > 0, fbatch6_kit)
fb6_control_vec <- as.vector(taxa_names(fbatch6_kit)) 
fb6_vec <- as.vector(taxa_names(fbatch6)) 
fb6_keep <- setdiff(fb6_vec, fb6_control_vec)
fb6_clean <- prune_taxa(fb6_keep, fbatch6)

# batch 7
fbatch7 = subset_samples(EX_ps, Fbatch == "7")  
fbatch7_kit = subset_samples(fbatch7, Type == "NegCon")
fbatch7_kit <- prune_taxa(taxa_sums(fbatch7_kit) > 0, fbatch7_kit)
fb7_control_vec <- as.vector(taxa_names(fbatch7_kit)) 
fb7_vec <- as.vector(taxa_names(fbatch7)) 
fb7_keep <- setdiff(fb7_vec, fb7_control_vec)
fb7_clean <- prune_taxa(fb7_keep, fbatch7)

# batch 8
fbatch8 = subset_samples(EX_ps, Fbatch == "8")  
fbatch8_kit = subset_samples(fbatch8, Type == "NegCon")
fbatch8_kit <- prune_taxa(taxa_sums(fbatch8_kit) > 0, fbatch8_kit)
fb8_control_vec <- as.vector(taxa_names(fbatch8_kit)) 
fb8_vec <- as.vector(taxa_names(fbatch8)) 
fb8_keep <- setdiff(fb8_vec, fb8_control_vec)
fb8_clean <- prune_taxa(fb8_keep, fbatch8)

# batch 9
fbatch9 = subset_samples(EX_ps, Fbatch == "9")  
fbatch9_kit = subset_samples(fbatch9, Type == "NegCon")
fbatch9_kit <- prune_taxa(taxa_sums(fbatch9_kit) > 0, fbatch9_kit)
fb9_control_vec <- as.vector(taxa_names(fbatch9_kit)) 
fb9_vec <- as.vector(taxa_names(fbatch9)) 
fb9_keep <- setdiff(fb9_vec, fb9_control_vec)
fb9_clean <- prune_taxa(fb9_keep, fbatch9)

# batch 10
fbatch10 = subset_samples(EX_ps, Fbatch == "10")  
fbatch10_kit = subset_samples(fbatch10, Type == "NegCon")
fbatch10_kit <- prune_taxa(taxa_sums(fbatch10_kit) > 0, fbatch10_kit)
fb10_control_vec <- as.vector(taxa_names(fbatch10_kit)) 
fb10_vec <- as.vector(taxa_names(fbatch10)) 
fb10_keep <- setdiff(fb10_vec, fb10_control_vec)
fb10_clean <- prune_taxa(fb10_keep, fbatch10)

# batch 11
fbatch11 = subset_samples(EX_ps, Fbatch == "11")  
fbatch11_kit = subset_samples(fbatch11, Type == "NegCon")
fbatch11_kit <- prune_taxa(taxa_sums(fbatch11_kit) > 0, fbatch11_kit)
fb11_control_vec <- as.vector(taxa_names(fbatch11_kit)) 
fb11_vec <- as.vector(taxa_names(fbatch11)) 
fb11_keep <- setdiff(fb11_vec, fb11_control_vec)
fb11_clean <- prune_taxa(fb11_keep, fbatch11)

# batch 12
#fbatch12 = subset_samples(EX_ps, Fbatch == "12")  
#fbatch12_kit = subset_samples(fbatch12, Type == "NegCon")
#fbatch12_kit <- prune_taxa(taxa_sums(fbatch12_kit) > 0, fbatch12_kit)
#fb12_control_vec <- as.vector(taxa_names(fbatch12_kit)) 
#fb12_vec <- as.vector(taxa_names(fbatch12)) 
#fb12_keep <- setdiff(fb12_vec, fb12_control_vec)
#fb12_clean <- prune_taxa(fb12_keep, fbatch12)

# batch 13
fbatch13 = subset_samples(EX_ps, Fbatch == "13")  
fbatch13_kit = subset_samples(fbatch13, Type == "NegCon")
fbatch13_kit <- prune_taxa(taxa_sums(fbatch13_kit) > 0, fbatch13_kit)
fb13_control_vec <- as.vector(taxa_names(fbatch13_kit)) 
fb13_vec <- as.vector(taxa_names(fbatch13)) 
fb13_keep <- setdiff(fb13_vec, fb13_control_vec)
fb13_clean <- prune_taxa(fb13_keep, fbatch13)

# batch 14
fbatch14 = subset_samples(EX_ps, Fbatch == "14")  
fbatch14_kit = subset_samples(fbatch14, Type == "NegCon")
fbatch14_kit <- prune_taxa(taxa_sums(fbatch14_kit) > 0, fbatch14_kit)
fb14_control_vec <- as.vector(taxa_names(fbatch14_kit)) 
fb14_vec <- as.vector(taxa_names(fbatch14)) 
fb14_keep <- setdiff(fb14_vec, fb14_control_vec)
fb14_clean <- prune_taxa(fb14_keep, fbatch14)

# batch 15
fbatch15 = subset_samples(EX_ps, Fbatch == "15")  
fbatch15_kit = subset_samples(fbatch15, Type == "NegCon")
fbatch15_kit <- prune_taxa(taxa_sums(fbatch15_kit) > 0, fbatch15_kit)
fb15_control_vec <- as.vector(taxa_names(fbatch15_kit)) 
fb15_vec <- as.vector(taxa_names(fbatch15)) 
fb15_keep <- setdiff(fb15_vec, fb15_control_vec)
fb15_clean <- prune_taxa(fb15_keep, fbatch15)

# batch 0

fbatch0 = subset_samples(EX_ps, Fbatch == "0")  
fbatch0_kit = subset_samples(fbatch0, Type == "NegCon")
fbatch0_kit <- prune_taxa(taxa_sums(fbatch0_kit) > 0, fbatch0_kit)
fb0_control_vec <- as.vector(taxa_names(fbatch0_kit)) 
fb0_vec <- as.vector(taxa_names(fbatch0)) 
fb0_keep <- setdiff(fb0_vec, fb0_control_vec)
fb0_clean <- prune_taxa(fb0_keep, fbatch0)

```

```{r}
# Merge the phyloseq objects back together, then remove any blank taxa or samples
EX_ps_NC_batch_clean <- merge_phyloseq(fb0_clean, fb2_clean, fb3_clean, fb5_clean, fb6_clean, fb7_clean, fb8_clean, fb9_clean, fb11_clean, fb14_clean, fb15_clean) 

# Clean out taxa/SV columns that are no longer present
EX_ps_NC_batch_clean <- prune_taxa(taxa_sums(EX_ps_NC_batch_clean) > 0, EX_ps_NC_batch_clean) 

EX_ps_NC_batch_clean <- prune_samples(sample_sums(EX_ps_NC_batch_clean) > 0, EX_ps_NC_batch_clean)
EX_ps_NC_batch_clean
```


```{r recheck_ordination, echo = FALSE}
# Check simple ordination again to see if decontam worked

EX_cleaner.ord <- ordinate(EX_ps_NC_batch_clean, method ="PCoA", "jaccard", binary = TRUE) 
 
plot_ordination(EX_ps_NC_batch_clean, EX_cleaner.ord, type="samples", color="Fbatch", title="Prelim 12S Jaccard Binary Ordination Post-Decontam")
```


# Remove Unwanted Taxa with Dplyr


```{r remove_taxa, echo = FALSE}
# Remove species that contain either Bacteria as a Kingdom or Homo as a genus. Not interested in either Bacteria or Human DNA results
EX_ps_clean <- EX_ps_NC_batch_clean %>% 
  subset_taxa(Kingdom != "Bacteria" & Genus != "Homo") 

```

```{r clean_columns, echo = FALSE}
# Remove empty rows made after removing Bacteria and Homo
EX_ps_clean <- prune_taxa(taxa_sums(EX_ps_clean) > 0, EX_ps_clean) 
EX_ps_clean <- prune_samples(sample_sums(EX_ps_clean) > 0, EX_ps_clean)

EX_ps_clean
saveRDS(EX_ps_clean, 'C:/Users/bydav/Desktop/12SPrelim_EX_ps_clean.RDS')
```


