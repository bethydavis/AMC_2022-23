#rownames(track) <- sample.names
head(track12)
View(track12)
# Save the results of the workflow verification
write.csv(track12, file.path(path_outputs, "12S_WorkflowVerification.csv"))
View(track12)
View(filtout12sync)
GNRMaineSpecies_May2024 <- readRDS("C:/Users/bydav/Desktop/SpeciesListCleaning_Complete/outputs/GNRMaineSpecies_May2024.RDS")
View(GNRMaineSpecies_May2024)
source("AMCCOI_config.R")
# Specify file name formats
fnsBF <- list.files(path_rawBF)
fastqsBF <- fnsBF[grepl('.gz$', fnsBF)]
fnsBR <- list.files(path_rawBR)
fastqsBR <- fnsBR[grepl('.gz$', fnsBR)]
# The file paths still include the desktop.ini file, so let's specify a file path to lead future code only to the fastq files in the folder
fnsBFisolate <- file.path(path_rawBF, fastqsBF)
fnsBRisolate <- file.path(path_rawBR, fastqsBR)
# Set sample names to a vector
# Remove path and the .gz extension
# Repeat file_path_sans_ext to also remove the .fastq
namesBFfast <- tools::file_path_sans_ext(basename(fastqsBF))
namesBF <- tools::file_path_sans_ext(namesBFfast)
namesBRfast <- tools::file_path_sans_ext(basename(fastqsBR))
# Repeat file_path_sans_ext to also remove the .fastq
namesBR <- tools::file_path_sans_ext(namesBRfast)
filtF <- file.path(path_filtBF, "filtered", paste0(sample.names, "_F_filt.fastq.gz"))
filtoutB <- filterAndTrim(file.path(path_rawBF, fastqsBF), file.path(path_filtBF, paste0(namesBF, "filt.fastq.gz")), file.path(path_rawBR, fastqsBR), file.path(path_filtBR, paste0(namesBR, "filt.fastq.gz")), trimLeft = c(20,20), trimRight=c(20,50), maxN=0, maxEE=c(2,2), verbose=TRUE)
saveRDS(filtoutB, "G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/COI/5-May03-2024/FiltOutput.rds")
1+1
saveRDS(filtoutB, "G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/COI/5-May03-2024/FiltOutput.rds")
saveRDS(filtoutB, "G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/COIB/5-May03-2024/FiltOutput.rds")
filtoutB
dim(filtoutB)
# Order by filtered read amount
filtoutB[order(filtoutB[,2], decreasing=FALSE),]
# Compare total raw in and filtered out read amounts
colSums(filtoutB)
write.csv(filtoutB, file.path(path_outputs, "FiltOutput.csv"))
filttrendB <- ggplot(as.data.frame(filtoutB)) + geom_point(aes(row.names(filtoutB), reads.in), color = "blue") + geom_point(aes(row.names(filtoutB), reads.out), color = "orange") + ggtitle("Filter Trends for AMC BF2/BR2 Reads")
filttrendB
ggsave("FilterTrends.png", plot = filttrendB, path = path_outputs, width = 6, height = 4, units = "in")
set.seed(0743)
# BForward
#
# create a list of files in the path
filtnamesBFinter <- list.files(path_filtBF, full.names = TRUE)
# Specify I only want the files with the .gz extension
filtnamesBF <- filtnamesBFinter[grepl('.gz$', filtnamesBFinter)]
# Extract just the file name, not the path, and remove the .gz extension. This leaves on the .fastq extension
fastqfiltBF <- tools::file_path_sans_ext(basename(filtnamesBF))
# Remove the .fastq extension
namesBFfilt <- tools::file_path_sans_ext(basename(fastqfiltBF))
# BReverse
filtnamesBRinter <- list.files(path_filtBR, full.names = TRUE)
filtnamesBR <- filtnamesBRinter[grepl('.gz$', filtnamesBRinter)]
fastqfiltBR <- tools::file_path_sans_ext(basename(filtnamesBR))
namesBRfilt <- tools::file_path_sans_ext(basename(fastqfiltBR))
derepBF <- derepFastq(filtnamesBF, verbose = TRUE)
derepBR <- derepFastq(filtnamesBR, verbose = TRUE)
errBF <- learnErrors(derepBF, multithread = FALSE, randomize = TRUE)
saveRDS(errBF, "G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/COIB/5-May03-2024/ForwardError.rds")
ggsave("ForwardError.png", plot = errBF, path = path_outputs, width = 6, height = 4, units = "in")
ggsave("Forward_ErrorPlot.png", path = path_outputs, plotErrors(errBF, nominalQ = TRUE), width = 6, height = 4, units = "in")
errBR <- learnErrors(derepBR, multithread = FALSE, randomize = TRUE)
saveRDS(errBR, "G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/COIB/5-May03-2024/ReverseError.rds")
ggsave("Reverse_ErrorPlot.png", path = path_outputs, plotErrors(errBR, nominalQ = TRUE), width = 6, height = 4, units = "in")
# This takes a long time. If you have to do it again, include this:
beep(sound = "fanfare")
dadaBF <- dada(derepBF, err = errBF, multithread = FALSE)
print("dada BF finished")
beep(sound = "coin")
dadaBR <- dada(derepBR, err = errBR, multithread = FALSE)
print("dada BR finished")
beep(sound = "fanfare")
# Save all in case I need to reload the dada objects
saveRDS(dadaBF, "G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/COIB/5-May03-2024/BForward_SampleComp.rds")
saveRDS(dadaBR, "G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/COIB/5-May03-2024/BReverse_SampleComp.rds")
mergersB <- mergePairs(dadaBF, derepBF, dadaBR, derepBR, verbose = TRUE)
head(mergersB[[1]])
saveRDS(mergersB, "C:/Users/bydav/Desktop/MathFilterTestAMC/BMergedSampleComp.rds")
mergersB <- mergePairs(dadaBF, derepBF, dadaBR, derepBR, verbose = TRUE)
head(mergersB[[1]])
saveRDS(mergersB, "G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/COIB/5-May03-2024/BMergedSampleComp.rds")
seqtabB <- makeSequenceTable(mergersB)
dim(seqtabB)
saveRDS(seqtabB, "G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/COIB/5-May03-2024/BMerged Sequence Table.rds")
dim(seqtabB)
table(nchar(getSequences(seqtabB)))
seqtabB.nochim <- removeBimeraDenovo(seqtabB, method = "consensus", multithread = FALSE, verbose = TRUE)
dim(seqtabB.nochim)
saveRDS(seqtabB.nochim, "G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/COIB/5-May03-2024/BMerged Sequence No Chimera Table.rds")
beep(sound = "coin")
dim(seqtabB.nochim)
table(nchar(getSequences(seqtabB.nochim)))
getN <- function(x) sum(getUniques(x))
trackB <- cbind(filtoutBsync, sapply(dadaBF, getN), sapply(dadaBR, getN), sapply(mergersB, getN), rowSums(seqtabB.nochim))
getN <- function(x) sum(getUniques(x))
trackB <- cbind(filtoutB, sapply(dadaBF, getN), sapply(dadaBR, getN), sapply(mergersB, getN), rowSums(seqtabB.nochim))
colnames(trackB) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim")
head(trackB)
write.csv(trackB, file.path(path_outputs, "WorkflowVerification.csv"))
# Very slow and intensive
all.taxa <- assignTaxonomy(seqtabB.nochim, 'C:/Users/bydav/Desktop/RefDB_Dev/output/3-May19-2024/COI_REFDB.fasta', tryRC = TRUE, verbose = TRUE)
beep(sound = "fanfare")
write.csv(all.taxa, file.path(path_outputs, "COIAMC_AssignedTaxa.csv"))
source("AMC12S_config.R")
# Specify file name formats
fns12F <- list.files(path_raw12F)
fastqs12F <- fns12F[grepl('.gz$', fns12F)]
fns12R <- list.files(path_raw12R)
fastqs12R <- fns12R[grepl('.gz$', fns12R)]
# The file paths still include the desktop.ini file, so let's specify a file path to lead future code only to the fastq files in the folder
fns12Fisolate <- file.path(path_raw12F, fastqs12F)
fns12Risolate <- file.path(path_raw12R, fastqs12R)
# Set sample names to a vector, emove path and the .gz extension
names12Ffast <- tools::file_path_sans_ext(basename(fastqs12F))
# Repeat file_path_sans_ext to also remove the .fastq
names12F <- tools::file_path_sans_ext(names12Ffast)
names12Rfast <- tools::file_path_sans_ext(basename(fastqs12R))
names12R <- tools::file_path_sans_ext(names12Rfast)
path_filt12F
filtout12sync <- filterAndTrim(file.path(path_raw12F, fastqs12F), file.path(path_filt12F, paste0(names12F, "filt.fastq.gz")), file.path(path_raw12R, fastqs12R), file.path(path_filt12R, paste0(names12R, "filt.fastq.gz")), trimLeft = c(21,27), trimRight=c(80), maxN=0, maxEE=c(2,2), verbose=TRUE)
beep(sound = "fanfare")
dim(filtout12sync)
# Order by filtered read amount
filtout12sync[order(filtout12sync[,2], decreasing=FALSE),]
# Compare total raw in and filtered out read amounts
colSums(filtout12sync)
write.csv(filtout12sync, file.path(path_outputs, "FiltoutputTable.csv"))
filtout12sync
filttrend12sync <- ggplot(as.data.frame(filtout12sync)) + geom_point(aes(row.names(filtout12sync), reads.in), color = "blue") + geom_point(aes(row.names(filtout12sync), reads.out), color = "orange") + ggtitle("Filter Trends for AMC 12 Synced Forward Reads")
filttrend12sync
ggsave("FilterTrends_12Sync.png", plot = filttrend12sync, path = path_outputs, width = 6, height = 4, units = "in")
set.seed(9450)
# Set the names for the filtered files we'll be using
# create a list of files in the path
filtnames12Finter <- list.files(path_filt12F, full.names = TRUE)
# Specify I only want the files with the .gz extension
filtnames12F <- filtnames12Finter[grepl('.gz$', filtnames12Finter)]
# Extract just the file name, not the path, and remove the .gz extension. This leaves on the .fastq extension
fastqfilt12F <- tools::file_path_sans_ext(basename(filtnames12F))
# Remove the .fastq extension
names12Ffilt <- tools::file_path_sans_ext(basename(fastqfilt12F))
# 12Reverse
filtnames12Rinter <- list.files(path_filt12R, full.names = TRUE)
filtnames12R <- filtnames12Rinter[grepl('.gz$', filtnames12Rinter)]
fastqfilt12R <- tools::file_path_sans_ext(basename(filtnames12R))
names12Rfilt <- tools::file_path_sans_ext(basename(fastqfilt12R))
derep12F <- derepFastq(filtnames12F, verbose=TRUE)
derep12R <- derepFastq(filtnames12R, verbose=TRUE)
# Forward error rates
err12F <- learnErrors(derep12F, multithread = FALSE, randomize = TRUE)
saveRDS(err12F, "G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/12S/6-Jun03-2024/12Forward_Error.rds")
ggsave("12Forward_ErrorPlot.png", path = path_outputs, plotErrors(err12F, nominalQ = TRUE), width = 6, height = 4, units = "in")
# Reverse error rates
err12R <- learnErrors(derep12R, multithread = FALSE, randomize = TRUE)
saveRDS(err12R, "G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/12S/6-Jun03-2024/12Reverse_Error.rds")
ggsave("12Reverse_ErrorPlot.png", path = path_outputs, plotErrors(err12R, nominalQ = TRUE), width = 6, height = 4, units = "in")
# This takes a long time. If you have to do it again, include this:
beep(sound = "fanfare")
dada12F <- dada(derep12F, err = err12F, multithread = FALSE)
print("dada 12F finished")
beep(sound = "coin")
dada12R <- dada(derep12R, err = err12R, multithread = FALSE)
print("dada 12R finished")
beep(sound = "fanfare")
# Save all in case I need to reload the dada objects
saveRDS(dada12F, "G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/12S/6-Jun03-2024/12Forward_SampleComp.rds")
saveRDS(dada12R, "G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/12S/6-Jun03-2024/12Reverse_SampleComp.rds")
mergers12 <- mergePairs(dada12F, path_filt12F, dada12R, path_filt12R, verbose=TRUE)
# Update formatting into a matrix array
mergers12 <- makeSequenceTable(mergers12)
# Inspect the merger data.frame from the first sample
head(mergers12[[1]])
saveRDS(mergers12, "G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/12S/6-Jun03-2024/12MergedSampleComp.rds")
seqtab12.nochim <- removeBimeraDenovo(mergers12, method = "consensus", multithread = FALSE, verbose = TRUE)
# Save output
saveRDS(seqtab12.nochim, "G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/12S/6-Jun03-2024/12Merged Sequence No Chimera Table.rds")
beep(sound = "coin")
getN <- function(x) sum(getUniques(x))
track12 <- cbind(filtout12sync, sapply(dada12F, getN), sapply(dada12R, getN), sapply(mergers12, getN), rowSums(seqtab12.nochim))
# Very slow and intensive
all.taxa <- assignTaxonomy(seqtab12.nochim, 'C:/Users/bydav/Desktop/RefDB_Dev/output/2-May17-2024/12S_REFDB.fasta', tryRC = TRUE, verbose = TRUE)
beep(sound = "fanfare")
write.csv(all.taxa, file.path(path_outputs, "12SAMC_AssignedTaxa.csv"), row.names = FALSE)
installed.packages()
version
# Set version and date for each time the analysis script is run - SET THIS EVERY TIME YOU RUN A NEW SET
versiondate <- c("6-Jun03-2024/")
source("C:/Users/bydav/Desktop/GitHub/UM_FSM_AMC22-23/AMC12S_config.R")
packages
installed.packages(packages)
package_version(packages)
package_version(ggplot2)
package_version("ggplot2")
source("AMC12S_config.R")
dada12F <- readRDS("G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/12S/6-Jun03-2024/12Forward_SampleComp.rds")
dada12R <- readRDS("G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/12S/6-Jun03-2024/12Reverse_SampleComp.rds")
filtout12sync <- read.csv(file.path(path_outputs, "FiltoutputTable.csv"))
mergers12 <- mergePairs(dada12F, path_filt12F, dada12R, path_filt12R, verbose=TRUE)
# Update formatting into a matrix array
seqtab <- makeSequenceTable(mergers12)
# Inspect the merger data.frame from the first sample
head(seqtab[[1]])
saveRDS(seqtab, "G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/12S/6-Jun03-2024/12MergedSampleComp.rds")
seqtab12.nochim <- removeBimeraDenovo(seqtab, method = "consensus", multithread = FALSE, verbose = TRUE)
# Save output
saveRDS(seqtab12.nochim, "G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/12S/6-Jun03-2024/12Merged Sequence No Chimera Table.rds")
beep(sound = "coin")
getN <- function(x) sum(getUniques(x))
track12 <- cbind(filtout12sync, sapply(dada12F, getN), sapply(dada12R, getN), sapply(mergers12, getN), rowSums(seqtab12.nochim))
length(dada12F) = length(filtout12sync)
View(dada12F)
length(dada12R) = length(filtout12sync)
length(seqtab12.nochim) = length(filtout12sync)
length(mergers12) = length(filtout12sync)
track12 <- cbind(filtout12sync, sapply(dada12F, getN), sapply(dada12R, getN), sapply(mergers12, getN), rowSums(seqtab12.nochim))
seqtab12.nochim <- readRDS("G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/12S/6-Jun03-2024/12Merged Sequence No Chimera Table.rds")
# Update formatting into a matrix array
seqtab <- makeSequenceTable(mergers12)
seqtab <- readRDS("G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/12S/6-Jun03-2024/12MergedSampleComp.rds")
dada12F <- readRDS("G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/12S/6-Jun03-2024/12Forward_SampleComp.rds")
dada12R <- readRDS("G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/12S/6-Jun03-2024/12Reverse_SampleComp.rds")
track12 <- cbind(filtout12sync, sapply(dada12F, getN), sapply(dada12R, getN), sapply(seqtab, getN), rowSums(seqtab12.nochim))
source("AMCCOI_config.R")
all.taxa <- read.csv(file.path(path_outputs, "COIAMC_AssignedTaxa.csv"))
row.names(all.taxa)
all.taxa[1]
seqtabB.nochim <- readRDS("G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/COIB/5-May03-2024/BMerged Sequence No Chimera Table.rds")
all.taxa <- data.frame(all.taxa, row.names = 1)
row.names(all.taxa)
# Identify metadata and reference database locations
meta <- read.csv("G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/AMCMeta.csv")
row.names(seqtabB.nochim)
row.names(meta)
meta <- data.frame(meta, row.names = 1)
row.names(meta)
row.names(meta) == row.names(seqtabB.nochim)
# Repeat file_path_sans_ext to also remove the .fastq
namesmetaI <- tools::file_path_sans_ext(basename(row.names(meta)))
namesmetaI
namesmeta <- tools::file_path_sans_ext(namesmetaI)
namesmeta
regexp <- "([[:alnum:]]+_)[[:alnum:]]+"
# process string
testnamemeta <- (str_extract(namesmeta, regexp))
library(stringr)
regexp <- "([[:alnum:]]+_)[[:alnum:]]+"
# process string
testnamemeta <- (str_extract(namesmeta, regexp))
testnamemeta
alltaxa <- data.frame(all.taxa, row.names = testnamemeta)
alltaxa <- data.frame(all.taxa)
row.names(alltaxa) <- testnamemeta
row.names(alltaxa) <- c(testnamemeta)
rownames(alltaxa) <- c(testnamemeta)
row.names(meta)
# Repeat file_path_sans_ext to also remove the .fastq
row.names(meta) <- tools::file_path_sans_ext(basename(row.names(meta)))
rownames(alltaxa) <- testnamemeta
row.names(alltaxa) <- c("testnamemeta")
row.names(alltaxa) <- c(testnamemeta)
View(alltaxa)
row.names(meta) <- c(testnamemeta)
View(meta)
row.names(meta) <- testnamemeta
# Identify metadata and reference database locations
meta <- read.csv("G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/AMCMeta.csv")
meta$sample <- c(testnamemeta)
meta$sample <- testnamemeta
# Repeat file_path_sans_ext to also remove the .fastq
meta$sample <- tools::file_path_sans_ext(basename(meta$sample))
# Repeat file_path_sans_ext to also remove the .fastq
meta$sample <- tools::file_path_sans_ext(basename(sample))
source("AMC12S_config.R")
seqtab12.nochim <- readRDS("G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/12S/6-Jun03-2024/12Merged Sequence No Chimera Table.rds")
read.csv(file.path(path_outputs, "12SAMC_AssignedTaxa.csv"), header = TRUE)
# Very slow and intensive
all.taxa <- assignTaxonomy(seqtab12.nochim, 'C:/Users/bydav/Desktop/RefDB_Dev/output/2-May17-2024/12S_REFDB.fasta', tryRC = TRUE, verbose = TRUE)
beep(sound = "fanfare")
write.csv(all.taxa, file.path(path_outputs, "12SAMC_AssignedTaxa.csv"))
row.names(all.taxa)
row.names(seqtab12.nochim)
row.names(meta)
meta1 <- df(meta, row.names = 1)
meta2 <- data.frame(meta, row.names = 1)
source("AMCCOI_config.R")
seqtabB.nochim <- readRDS("G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/COIB/5-May03-2024/BMerged Sequence No Chimera Table.rds")
row.names(seqtabB.nochim)
rownames <- row.names(seqtabB.nochim)
regexp <- "([[:alnum:]]+_)[[:alnum:]]+"
# process string
newnames <- (str_extract(rownames, regexp))
row.names(seqtabB.nochim) <- newnames
row.names(meta)
row.names(seqtabB.nochim) == row.names(meta)
row.names(seqtabB.nochim)
all.taxa <- read.csv(file.path(path_outputs, "COIAMC_AssignedTaxa.csv"))
# Create phyloseq object with all samples
EX_ps <- phyloseq(otu_table(seqtabB.nochim, taxa_are_rows=FALSE), sample_data(meta), tax_table(all.taxa))
taxa_names()
View(all.taxa)
# Create phyloseq object with all samples
EX_ps <- phyloseq(otu_table(seqtabB.nochim, taxa_are_rows=FALSE), sample_data(meta), tax_table(as.matrix)all.taxa)))
# Create phyloseq object with all samples
EX_ps <- phyloseq(otu_table(seqtabB.nochim, taxa_are_rows=FALSE), sample_data(meta), tax_table(as.matrix(all.taxa)))
View(seqtabB.nochim)
class(seqtabB.nochim)
class(meta)
class(all.taxa)
# Create phyloseq object with all samples
EX_ps <- phyloseq(otu_table(seqtabB.nochim, taxa_are_rows=FALSE), sample_data(as.matrix(meta)), tax_table(as.matrix(all.taxa)))
# Create phyloseq object with all samples
EX_ps <- phyloseq(otu_table(seqtabB.nochim, taxa_are_rows=FALSE), sample_data(meta), tax_table(as.matrix(all.taxa)))
View(seqtabB.nochim)
source("AMC12S_config.R")
seqtab12.nochim <- readRDS("G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/12S/6-Jun03-2024/12Merged Sequence No Chimera Table.rds")
row.names(seqtab12.nochim)
rownames <- row.names(seqtab12.nochim)
regexp <- "([[:alnum:]]+_)[[:alnum:]]+"
# process string
newnames <- (str_extract(rownames, regexp))
row.names(seqtab12.nochim) <- newnames
row.names(seqtab12.nochim)
row.names(meta)
# Identify metadata and reference database locations
meta <- read.csv("G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/AMCMeta.csv", header = TRUE, row.names=1)
row.names(meta)
all.taxa <- read.csv(file.path(path_outputs, "12SAMC_AssignedTaxa.csv"))
# Create phyloseq object with all samples
EX_ps <- phyloseq(otu_table(seqtab12.nochim, taxa_are_rows=FALSE), sample_data(meta), tax_table(all.taxa))
# Create phyloseq object with all samples
EX_ps <- phyloseq(otu_table(seqtab12.nochim, taxa_are_rows=FALSE), sample_data(meta), tax_table(as.matrix(all.taxa)))
View(seqtab12.nochim)
View(all.taxa)
# config file with paths and versioning
source("AMCCOI_config.R")
# File with previous outputs to make reloading easier
source("AMCCOI_reload.R")
# I'd like to make a stacked bar plot, before any taxa-filtering, of the read abundances
# Set function to make a proportional graph
EX_ps.func <- transform_sample_counts(EX_ps, function(x) x / sum(x) )
# Plot based on Phylum
plot_bar(EX_ps.func, fill="Phylum") + ggtitle("Proportion by Phylum of Identified Reads - 12S")
# Warning: Removed 143 rows containing missing values or values outside the scale range (`geom_bar()`).
# Save plot
#ggsave("PreDecontam_IDProportions.png", path = path_outputs, plot_bar(EX_ps.func, fill="Phylum") + ggtitle("Proportion by Phylum of Identified Reads"), width = 7, height = 4, units = "in")
# Save plot
ggsave("PreDecontam_IDProportions.png", path = path_outputs, plot_bar(EX_ps.func, fill="Phylum") + ggtitle("Proportion by Phylum of Identified Reads"), width = 7, height = 4, units = "in")
# Config file with paths and versioning
source("AMC12S_config.R")
# Reload file with paths to previous outputs
source("AMC12S_reload.R")
# I'd like to make a stacked bar plot, before any taxa-filtering, of the read abundances
# Set function to make a proportional graph
EX_ps.func <- transform_sample_counts(EX_ps, function(x) x / sum(x) )
# Plot based on Phylum
plot_bar(EX_ps.func, fill="Phylum") + ggtitle("Proportion by Phylum of Identified Reads - COI")
# Warning: Removed 79588 rows containing missing values or values outside the scale range (`geom_bar()`).
# Save plot
ggsave("PreDecontam_IDProportions.png", path = path_outputs, plot_bar(EX_ps.func, fill="Phylum") + ggtitle("Proportion by Phylum of Identified Reads"), width = 7, height = 4, units = "in")
# config file with paths and versioning
source("AMCCOI_config.R")
# File with previous outputs to make reloading easier
source("AMCCOI_reload.R")
# Update the all.taxa row names to be the actual sequences
all.taxa <- data.frame(all.taxa, row.names = 1)
# Order seqtab.nochim by row names
seqtabB.nochim <- seqtabB.nochim[order(row.names(seqtabB.nochim)), ]
# Order the meta file by sample name
meta <- meta[order(meta$sample), ]
# Remove the row(s) associated with dropped sample(s) from the meta spreadsheet - the only way I can do this is one row at a time
meta2 <- subset(meta, sample != "AMC22_AB01")
meta2 <- subset(meta2, sample != "AMC23_AB04")
meta2 <- subset(meta2, sample != "AMC23_MB09")
# Set the sample column as row.names
meta <- data.frame(meta2, row.names = 1)
# Order the meta file by row.names
meta <- meta[order(row.names(meta)), ]
# Make sure all samples in seqtab.nochim match and are in the same order as in meta, because the next step is a flat replacement of row.names
row.names(seqtabB.nochim) <- row.names(meta)
row.names(seqtabB.nochim)
# Create phyloseq object with all samples
EX_ps <- phyloseq(otu_table(seqtabB.nochim, taxa_are_rows=FALSE), sample_data(meta), tax_table(as.matrix(all.taxa)))
# SAVE
saveRDS(EX_ps, "G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/COIB/5-May03-2024/InitialPhyloseq.rds")
# SAVE
saveRDS(EX_ps, "G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/COIB/5-May03-2024/InitialPhyloseq.rds")
chek <- readRDS("G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/COIB/5-May03-2024/InitialPhyloseq.rds")
View(chek)
# subset each DNA extraction batch
batch1 = subset_samples(EX_ps, Ebatch == "1")
batch2 = subset_samples(EX_ps, Ebatch == "2")
batch3 = subset_samples(EX_ps, Ebatch == "3")
batch4 = subset_samples(EX_ps, Ebatch == "4")
batch5 = subset_samples(EX_ps, Ebatch == "5")
batch6 = subset_samples(EX_ps, Ebatch == "6")
batch7 = subset_samples(EX_ps, Ebatch == "7")
batch8 = subset_samples(EX_ps, Ebatch == "8")
batch9 = subset_samples(EX_ps, Ebatch == "9")
batch10 = subset_samples(EX_ps, Ebatch == "10")
# subset controls and prune to only those taxa
batch1_sub = subset_samples(batch1, Type == "NegCon")
batch2_sub = subset_samples(batch2, Type == "NegCon")
batch3_sub = subset_samples(batch3, Type == "NegCon")
batch4_sub = subset_samples(batch4, Type == "NegCon")
batch5_sub = subset_samples(batch5, Type == "NegCon")
batch6_sub = subset_samples(batch6, Type == "NegCon")
batch7_sub = subset_samples(batch7, Type == "NegCon")
batch8_sub = subset_samples(batch8, Type == "NegCon")
batch9_sub = subset_samples(batch9, Type == "NegCon")
batch10_sub = subset_samples(batch10, Type == "NegCon")
batch1_sub <- prune_taxa(taxa_sums(batch1_sub) > 0, batch1_sub)
batch2_sub <- prune_taxa(taxa_sums(batch2_sub) > 0, batch2_sub)
batch3_sub <- prune_taxa(taxa_sums(batch3_sub) > 0, batch3_sub)
batch4_sub <- prune_taxa(taxa_sums(batch4_sub) > 0, batch4_sub)
batch5_sub <- prune_taxa(taxa_sums(batch5_sub) > 0, batch5_sub)
batch6_sub <- prune_taxa(taxa_sums(batch6_sub) > 0, batch6_sub)
batch7_sub <- prune_taxa(taxa_sums(batch7_sub) > 0, batch7_sub)
batch8_sub <- prune_taxa(taxa_sums(batch8_sub) > 0, batch8_sub)
batch9_sub <- prune_taxa(taxa_sums(batch9_sub) > 0, batch9_sub)
# Batch 10's control has no reads, can keep all of batch10
#batch10_sub <- prune_taxa(taxa_sums(batch10_sub) > 0, batch10_sub)
# Make the taxa names into a vector so you can remove them, then use the keep vector for the prune taxa argument, because it wants the argument to be true (matching), and repeat for both batches
batch1_ctrl <- as.vector(taxa_names(batch1_sub))
batch1_vec <- as.vector(taxa_names(batch1))
batch1_kp <- setdiff(batch1_vec, batch1_ctrl)
batch1_clean <- prune_taxa(batch1_kp, batch1)
batch2_ctrl <- as.vector(taxa_names(batch2_sub))
batch2_vec <- as.vector(taxa_names(batch2))
batch2_kp <- setdiff(batch2_vec, batch2_ctrl)
batch2_clean <- prune_taxa(batch2_kp, batch2)
batch3_ctrl <- as.vector(taxa_names(batch3_sub))
batch3_vec <- as.vector(taxa_names(batch3))
batch3_kp <- setdiff(batch3_vec, batch3_ctrl)
batch3_clean <- prune_taxa(batch3_kp, batch3)
batch4_ctrl <- as.vector(taxa_names(batch4_sub))
batch4_vec <- as.vector(taxa_names(batch4))
batch4_kp <- setdiff(batch4_vec, batch4_ctrl)
batch4_clean <- prune_taxa(batch4_kp, batch4)
batch5_ctrl <- as.vector(taxa_names(batch5_sub))
batch5_vec <- as.vector(taxa_names(batch5))
batch5_kp <- setdiff(batch5_vec, batch5_ctrl)
batch5_clean <- prune_taxa(batch5_kp, batch5)
batch6_ctrl <- as.vector(taxa_names(batch6_sub))
batch6_vec <- as.vector(taxa_names(batch6))
batch6_kp <- setdiff(batch6_vec, batch6_ctrl)
batch6_clean <- prune_taxa(batch6_kp, batch6)
batch7_ctrl <- as.vector(taxa_names(batch7_sub))
batch7_vec <- as.vector(taxa_names(batch7))
batch7_kp <- setdiff(batch7_vec, batch7_ctrl)
batch7_clean <- prune_taxa(batch7_kp, batch7)
batch8_ctrl <- as.vector(taxa_names(batch8_sub))
batch8_vec <- as.vector(taxa_names(batch8))
batch8_kp <- setdiff(batch8_vec, batch8_ctrl)
batch8_clean <- prune_taxa(batch8_kp, batch8)
batch9_ctrl <- as.vector(taxa_names(batch9_sub))
batch9_vec <- as.vector(taxa_names(batch9))
batch9_kp <- setdiff(batch9_vec, batch9_ctrl)
batch9_clean <- prune_taxa(batch9_kp, batch9)
# Save the phyloseq object of identified contaminants
pstrimmed <- merge_phyloseq(batch1_sub, batch2_sub, batch3_sub, batch4_sub, batch5_sub, batch6_sub, batch7_sub, batch8_sub, batch9_sub)
saveRDS(pstrimmed, "G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/COIB/5-May03-2024/DecontamRemoved.rds")
# Merge the phyloseq objects back together, then remove any blank taxa or samples
ps_clean <- merge_phyloseq(batch1_clean, batch2_clean, batch3_clean, batch4_clean, batch5_clean, batch6_clean, batch7_clean, batch8_clean, batch9_clean, batch10)
# Clean out taxa/SV columns that are no longer present
ps_clean <- prune_taxa(taxa_sums(ps_clean) > 0, ps_clean)
ps_clean <- prune_samples(sample_sums(ps_clean) > 0, ps_clean)
ps_clean
# Save in case R crashes again
saveRDS(ps_clean, "G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/COIB/5-May03-2024/Intermediate.rds")
ps_clean.stack <- transform_sample_counts(ps_clean, function(x) x / sum(x) )
# Plot based on Phylum
plot_bar(ps_clean.stack, fill="Kingdom") + ggtitle("Proportion by Kingdom of Identified Reads - COI")
# Remove plant and others
psCOI <- ps_clean %>%
subset_taxa(Kingdom != "Ascomycota")
psCOI <- psCOI %>%
subset_taxa(Kingdom != "Bacillariophyta")
psCOI <- psCOI %>%
subset_taxa(Kingdom != "Basidiomycota")
psCOI <- psCOI %>%
subset_taxa(Kingdom != "Chlorophyta")
psCOI <- psCOI %>%
subset_taxa(Kingdom != "Oomycota")
psCOI <- psCOI %>%
subset_taxa(Kingdom != "Pseudomonadota")
psCOI <- psCOI %>%
subset_taxa(Kingdom != "Rhodophyta")
psCOI <- psCOI %>%
subset_taxa(Kingdom != "Rotifera")
psCOI <- psCOI %>%
subset_taxa(Kingdom != "Tubulinea")
psCOI <- psCOI %>%
subset_taxa(Kingdom != "Streptophyta")
psCOI <- prune_taxa(taxa_sums(psCOI) > 0, psCOI)
psCOI <- prune_samples(sample_sums(psCOI) > 0, psCOI)
psCOI.stack <- transform_sample_counts(psCOI, function(x) x / sum(x) )
# Plot based on Class
plot_bar(psCOI.stack, fill="Class") + ggtitle("Proportion of Cleaned Reads by Class.png")
psCOI
ggsave("CleanedClassIDs.png", path = path_outputs, plot_bar(psCOI.stack, fill="Class") + ggtitle("Proportion of Cleaned Reads by Class.png") + ggtitle("COI Identified Clean Reads"), width = 8, height = 5, units = "in")
saveRDS(psCOI, "G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/COIB/5-May03-2024/CleanPhyloseq.RDS")
psCOI <- prune_taxa(taxa_sums(psCOI) > 0, psCOI)
psCOI <- prune_samples(sample_sums(psCOI) > 0, psCOI)
psCOI.stack <- transform_sample_counts(psCOI, function(x) x / sum(x) )
# Plot based on Class
plot_bar(psCOI.stack, fill="Class") + ggtitle("Proportion of Cleaned Reads by Class.png")
psCOI
ggsave("CleanedClassIDs.png", path = path_outputs, plot_bar(psCOI.stack, fill="Class") + ggtitle("Proportion of Cleaned Reads by Class.png") + ggtitle("COI Identified Clean Reads"), width = 8, height = 5, units = "in")
saveRDS(psCOI, "G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/COIB/5-May03-2024/CleanPhyloseq.RDS")
