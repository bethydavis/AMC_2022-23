---
title: "AMCCOI"
author: "BYDavis"
date: "2024-04-17"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Markdown file to analyze AMC water eDNA samples, using Dr. Sue Ishaq's DNA Sequencing Analysis workflow (to start). 

Debugging statements are preceded with ###

# Set up packages and paths with config file
```{r COI_config}
source("AMCCOI_config.R")
```

Prior to this Rmd, the raw fastq files have been renamed in the repo UM_FSM_Cleaning

# Set folder paths and file types
```{r raw_paths, echo = FALSE}

# Specify file name formats
fnsBF <- list.files(path_rawBF)
fastqsBF <- fnsBF[grepl('.gz$', fnsBF)]

fnsBR <- list.files(path_rawBR)
fastqsBR <- fnsBR[grepl('.gz$', fnsBR)]

# The file paths still include the desktop.ini file, so let's specify a file path to lead future code only to the fastq files in the folder

fnsBFisolate <- file.path(path_rawBF, fastqsBF)
fnsBRisolate <- file.path(path_rawBR, fastqsBR)

# Set sample names to a vector
# Remove path and the .gz extension
# Repeat file_path_sans_ext to also remove the .fastq
namesBFfast <- tools::file_path_sans_ext(basename(fastqsBF))
namesBF <- tools::file_path_sans_ext(namesBFfast)

namesBRfast <- tools::file_path_sans_ext(basename(fastqsBR))
# Repeat file_path_sans_ext to also remove the .fastq
namesBR <- tools::file_path_sans_ext(namesBRfast)

```

The sample names are already set how I want them, so I won't use/adapt Sue's file name cleaning chunk (Clean File Names for Initial Load)

# Check Sequence Quality

Run 4 randomly selected quality profile plots per primer per read type (forward or reverse). Number will correspond to the file order. Min is set to 2 to avoid the desktop.ini file that GoogleDrive desktop creates from being chosen

```{r random_selection}
# Numbers for BF2 Forward reads:
sample(1:78, 6, replace = FALSE)
  # Results on 3/20/2024: 48 64 20 57 15 11

# Numbers for BF2 Reverse reads:
sample(1:78, 6, replace = FALSE)
  # Results on 3/20/2024: 15, 49, 56, 78, 11, 28
```

## NTS: keep working at cleaning out the 12S from here

5/03 note: run the plots again to standardize size
```{r}
# B Forward:
ggsave("BF2ForwardQuality_RNG48.png", plot = plotQualityProfile(fnsBFisolate[48]), path = path_outputs, width = 6, height = 4, units = "in")

ggsave("BF2ForwardQuality_RNG64.png", plot = plotQualityProfile(fnsBFisolate[64]), path = path_outputs, width = 6, height = 4, units = "in")

ggsave("BF2ForwardQuality_RNG20.png", plot = plotQualityProfile(fnsBFisolate[20]), path = path_outputs, width = 6, height = 4, units = "in")

ggsave("BF2ForwardQuality_RNG57.png", plot = plotQualityProfile(fnsBFisolate[57]), path = path_outputs, width = 6, height = 4, units = "in")

ggsave("BF2ForwardQuality_RNG15.png", plot = plotQualityProfile(fnsBFisolate[15]), path = path_outputs, width = 6, height = 4, units = "in")

ggsave("BF2ForwardQuality_RNG11.png", plot = plotQualityProfile(fnsBFisolate[11]), path = path_outputs, width = 6, height = 4, units = "in")

beep(sound = "fanfare")
```

```{r}
# B Reverse:
ggsave("BR2ReverseQuality_RNG15.png", plot = plotQualityProfile(fnsBRisolate[15]), path = path_outputs, width = 6, height = 4, units = "in")

ggsave("BR2ReverseQuality_RNG49.png", plot = plotQualityProfile(fnsBRisolate[49]), path = path_outputs, width = 6, height = 4, units = "in")

ggsave("BR2ReverseQuality_RNG56.png", plot = plotQualityProfile(fnsBRisolate[56]), path = path_outputs, width = 6, height = 4, units = "in")

ggsave("BR2ReverseQuality_RNG77.png", plot = plotQualityProfile(fnsBRisolate[77]), path = path_outputs, width = 6, height = 4, units = "in")

ggsave("BR2ReverseQuality_RNG11.png", plot = plotQualityProfile(fnsBRisolate[11]), path = path_outputs, width = 6, height = 4, units = "in")

ggsave("BR2ReverseQuality_RNG28.png", plot = plotQualityProfile(fnsBRisolate[28]), path = path_outputs, width = 6, height = 4, units = "in")

beep(sound = "fanfare")
```

The indexes and adapters have been removed from the sequence files, but the original primers are still attached. Need to account for their presence in the trim amounts and remove them.

BF2/BR2 COI Region: ~420 bp - this is longer than the cycle length, but should still provide 260bp of overlap

BF2 primer length: 20 -  GCHCCHGAYATRGCHTTYCC 

BR2 primer length: 20 -  TCDGGRTGNCCRAARAAYCA 


Given a desired score of 25+, trim reverse after 250 and forward after 280

# Begin filtering process

```{r filt12_both}
filtoutB <- filterAndTrim(file.path(path_rawBF, fastqsBF), file.path(path_filtBF, paste0(namesBF, "filt.fastq.gz")), file.path(path_rawBR, fastqsBR), file.path(path_filtBR, paste0(namesBR, "filt.fastq.gz")), trimLeft = c(20,20), trimRight=c(20,50), maxN=0, maxEE=c(2,2), verbose=TRUE) 

saveRDS(filtoutB, "G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/COIB/5-May03-2024/FiltOutput.rds")
```
AMC22_AB01 removed
AMC23_AB04 removed
AMC23_MB09 removed

# Explore filtered output 

Can look at the dimensions of each RDS output, and order by the filtered read amount, and/or look at the number of total raw reads compared to the filtered out reads

```{r assess filt_BF}
filtoutB
dim(filtoutB)

# Order by filtered read amount
filtoutB[order(filtoutB[,2], decreasing=FALSE),]

# Compare total raw in and filtered out read amounts
colSums(filtoutB)

write.csv(filtoutB, file.path(path_outputs, "FiltOutput.csv"))
```

# Look at filtered trends
```{r filtertrends}

filttrendB <- ggplot(as.data.frame(filtoutB)) + geom_point(aes(row.names(filtoutB), reads.in), color = "blue") + geom_point(aes(row.names(filtoutB), reads.out), color = "orange") + ggtitle("Filter Trends for AMC BF2/BR2 Reads")

filttrendB

ggsave("FilterTrends.png", plot = filttrendB, path = path_outputs, width = 6, height = 4, units = "in")
```


# Error Rates and Dereplication

First we need to set a seed and make sure the paths are all still set.

```{r error setup}
set.seed(0743)

# BForward
# 
# create a list of files in the path
filtnamesBFinter <- list.files(path_filtBF, full.names = TRUE)

# Specify I only want the files with the .gz extension
filtnamesBF <- filtnamesBFinter[grepl('.gz$', filtnamesBFinter)]

# Extract just the file name, not the path, and remove the .gz extension. This leaves on the .fastq extension
fastqfiltBF <- tools::file_path_sans_ext(basename(filtnamesBF))

# Remove the .fastq extension
namesBFfilt <- tools::file_path_sans_ext(basename(fastqfiltBF))

# BReverse
filtnamesBRinter <- list.files(path_filtBR, full.names = TRUE)
filtnamesBR <- filtnamesBRinter[grepl('.gz$', filtnamesBRinter)]
fastqfiltBR <- tools::file_path_sans_ext(basename(filtnamesBR))
namesBRfilt <- tools::file_path_sans_ext(basename(fastqfiltBR))
```

## Dereplication

This step comes from the dada2 workflow (https://bioconductor.org/packages/devel/bioc/vignettes/dada2/inst/doc/dada2-intro.html#learn-the-error-rates), not Sue's code

```{r derep}
derepBF <- derepFastq(filtnamesBF, verbose = TRUE)
derepBR <- derepFastq(filtnamesBR, verbose = TRUE)
```

Now that the names are set up, we can run the simulations to learn and estimate the number of errors in each filtered folder. This step is in Sue's code (and is the source of the saveRDS and plotErrors lines), but using the default parameters from the dada2 workflow

## Error Rates

```{r errorrates}
errBF <- learnErrors(derepBF, multithread = FALSE, randomize = TRUE)

saveRDS(errBF, "G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/COIB/5-May03-2024/ForwardError.rds")
ggsave("Forward_ErrorPlot.png", path = path_outputs, plotErrors(errBF, nominalQ = TRUE), width = 6, height = 4, units = "in") 


errBR <- learnErrors(derepBR, multithread = FALSE, randomize = TRUE)
saveRDS(errBR, "G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/COIB/5-May03-2024/ReverseError.rds")
ggsave("Reverse_ErrorPlot.png", path = path_outputs, plotErrors(errBR, nominalQ = TRUE), width = 6, height = 4, units = "in") 

# This takes a long time. If you have to do it again, include this:
beep(sound = "fanfare")
```

# Infer sample composition
```{r samplecomposition}
dadaBF <- dada(derepBF, err = errBF, multithread = FALSE)
print("dada BF finished")
beep(sound = "coin")

dadaBR <- dada(derepBR, err = errBR, multithread = FALSE)
print("dada BR finished")
beep(sound = "fanfare")

# Save all in case I need to reload the dada objects
saveRDS(dadaBF, "G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/COIB/5-May03-2024/BForward_SampleComp.rds")
saveRDS(dadaBR, "G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/COIB/5-May03-2024/BReverse_SampleComp.rds")
```


Merge paired reads

```{r}
mergersB <- mergePairs(dadaBF, derepBF, dadaBR, derepBR, verbose = TRUE)
head(mergersB[[1]])

saveRDS(mergersB, "G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/COIB/5-May03-2024/BMergedSampleComp.rds")
```

```{r seqtabB}
seqtabB <- makeSequenceTable(mergersB)
dim(seqtabB)
saveRDS(seqtabB, "G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/COIB/5-May03-2024/BMerged Sequence Table.rds")

dim(seqtabB)
table(nchar(getSequences(seqtabB)))
```

# Remove Chimeras 
```{r nochimB}
seqtabB.nochim <- removeBimeraDenovo(seqtabB, method = "consensus", multithread = FALSE, verbose = TRUE)
dim(seqtabB.nochim)
saveRDS(seqtabB.nochim, "G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/COIB/5-May03-2024/BMerged Sequence No Chimera Table.rds")

beep(sound = "coin")

dim(seqtabB.nochim)
table(nchar(getSequences(seqtabB.nochim)))
```

# Workflow Verification

```{r workflow_verification, echo = FALSE}
getN <- function(x) sum(getUniques(x))


trackB <- cbind(filtoutB, sapply(dadaBF, getN), sapply(dadaBR, getN), sapply(mergersB, getN), rowSums(seqtabB.nochim))

colnames(trackB) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim")
head(trackB)

write.csv(trackB, file.path(path_outputs, "WorkflowVerification.csv"))
```


# Assign Taxonomy

```{r assign_taxonomy, echo = FALSE}
# Very slow and intensive
all.taxa <- assignTaxonomy(seqtabB.nochim, 'C:/Users/bydav/Desktop/RefDB_Dev/output/3-May19-2024/COI_REFDB.fasta', tryRC = TRUE, verbose = TRUE)
beep(sound = "fanfare")

write.csv(all.taxa, file.path(path_outputs, "COIAMC_AssignedTaxa.csv"))
```

# Phyloseq

Load in a metadata file - make sure the sample names and order match between it and the seqtab
```{r name_check, include = FALSE}
row.names(seqtabB.nochim)
row.names(meta)


# Convince R by force that they match - this is a flat replacement, not a match-up
row.names(meta) <- row.names(seqtabB.nochim) 
```

```{r ps_object, echo = FALSE}
# Create phyloseq object with all samples
EX_ps <- phyloseq(otu_table(seqtabB.nochim, taxa_are_rows=FALSE), sample_data(meta), tax_table(all.taxa))
```


# Decontam with Negative Controls (Ishaq Method)
Clean all batches and then merge together into a clean phyloseq object - make this into a loop after MSWC
```{r}
# batch 3
fbatch3 = subset_samples(EX_ps, Fbatch == "3")  
fbatch3_kit = subset_samples(fbatch3, Type == "NegCon")
fbatch3_kit <- prune_taxa(taxa_sums(fbatch3_kit) > 0, fbatch3_kit)
fb3_control_vec <- as.vector(taxa_names(fbatch3_kit)) 
fb3_vec <- as.vector(taxa_names(fbatch3)) 
fb3_keep <- setdiff(fb3_vec, fb3_control_vec)
fb3_clean <- prune_taxa(fb3_keep, fbatch3)

# batch 4
#fbatch4 = subset_samples(EX_ps, Fbatch == "4")  
#fbatch4_kit = subset_samples(fbatch4, Type == "NegCon")
#fbatch4_kit <- prune_taxa(taxa_sums(fbatch4_kit) > 0, fbatch4_kit)
#fb4_control_vec <- as.vector(taxa_names(fbatch4_kit)) 
#fb4_vec <- as.vector(taxa_names(fbatch4)) 
#fb4_keep <- setdiff(fb4_vec, fb4_control_vec)
#fb4_clean <- prune_taxa(fb4_keep, fbatch4)

# batch 5
fbatch5 = subset_samples(EX_ps, Fbatch == "5")  
fbatch5_kit = subset_samples(fbatch5, Type == "NegCon")
fbatch5_kit <- prune_taxa(taxa_sums(fbatch5_kit) > 0, fbatch5_kit)
fb5_control_vec <- as.vector(taxa_names(fbatch5_kit)) 
fb5_vec <- as.vector(taxa_names(fbatch5)) 
fb5_keep <- setdiff(fb5_vec, fb5_control_vec)
fb5_clean <- prune_taxa(fb5_keep, fbatch5)

# batch 6
fbatch6 = subset_samples(EX_ps, Fbatch == "6")  
fbatch6_kit = subset_samples(fbatch6, Type == "NegCon")
fbatch6_kit <- prune_taxa(taxa_sums(fbatch6_kit) > 0, fbatch6_kit)
fb6_control_vec <- as.vector(taxa_names(fbatch6_kit)) 
fb6_vec <- as.vector(taxa_names(fbatch6)) 
fb6_keep <- setdiff(fb6_vec, fb6_control_vec)
fb6_clean <- prune_taxa(fb6_keep, fbatch6)

# batch 7
fbatch7 = subset_samples(EX_ps, Fbatch == "7")  
fbatch7_kit = subset_samples(fbatch7, Type == "NegCon")
fbatch7_kit <- prune_taxa(taxa_sums(fbatch7_kit) > 0, fbatch7_kit)
fb7_control_vec <- as.vector(taxa_names(fbatch7_kit)) 
fb7_vec <- as.vector(taxa_names(fbatch7)) 
fb7_keep <- setdiff(fb7_vec, fb7_control_vec)
fb7_clean <- prune_taxa(fb7_keep, fbatch7)

# batch 8
fbatch8 = subset_samples(EX_ps, Fbatch == "8")  
fbatch8_kit = subset_samples(fbatch8, Type == "NegCon")
fbatch8_kit <- prune_taxa(taxa_sums(fbatch8_kit) > 0, fbatch8_kit)
fb8_control_vec <- as.vector(taxa_names(fbatch8_kit)) 
fb8_vec <- as.vector(taxa_names(fbatch8)) 
fb8_keep <- setdiff(fb8_vec, fb8_control_vec)
fb8_clean <- prune_taxa(fb8_keep, fbatch8)

# batch 9
fbatch9 = subset_samples(EX_ps, Fbatch == "9")  
fbatch9_kit = subset_samples(fbatch9, Type == "NegCon")
fbatch9_kit <- prune_taxa(taxa_sums(fbatch9_kit) > 0, fbatch9_kit)
fb9_control_vec <- as.vector(taxa_names(fbatch9_kit)) 
fb9_vec <- as.vector(taxa_names(fbatch9)) 
fb9_keep <- setdiff(fb9_vec, fb9_control_vec)
fb9_clean <- prune_taxa(fb9_keep, fbatch9)

# batch 10
fbatch10 = subset_samples(EX_ps, Fbatch == "10")  
fbatch10_kit = subset_samples(fbatch10, Type == "NegCon")
fbatch10_kit <- prune_taxa(taxa_sums(fbatch10_kit) > 0, fbatch10_kit)
fb10_control_vec <- as.vector(taxa_names(fbatch10_kit)) 
fb10_vec <- as.vector(taxa_names(fbatch10)) 
fb10_keep <- setdiff(fb10_vec, fb10_control_vec)
fb10_clean <- prune_taxa(fb10_keep, fbatch10)

# batch 11
fbatch11 = subset_samples(EX_ps, Fbatch == "11")  
fbatch11_kit = subset_samples(fbatch11, Type == "NegCon")
fbatch11_kit <- prune_taxa(taxa_sums(fbatch11_kit) > 0, fbatch11_kit)
fb11_control_vec <- as.vector(taxa_names(fbatch11_kit)) 
fb11_vec <- as.vector(taxa_names(fbatch11)) 
fb11_keep <- setdiff(fb11_vec, fb11_control_vec)
fb11_clean <- prune_taxa(fb11_keep, fbatch11)

# batch 12
#fbatch12 = subset_samples(EX_ps, Fbatch == "12")  
#fbatch12_kit = subset_samples(fbatch12, Type == "NegCon")
#fbatch12_kit <- prune_taxa(taxa_sums(fbatch12_kit) > 0, fbatch12_kit)
#fb12_control_vec <- as.vector(taxa_names(fbatch12_kit)) 
#fb12_vec <- as.vector(taxa_names(fbatch12)) 
#fb12_keep <- setdiff(fb12_vec, fb12_control_vec)
#fb12_clean <- prune_taxa(fb12_keep, fbatch12)

# batch 13
fbatch13 = subset_samples(EX_ps, Fbatch == "13")  
fbatch13_kit = subset_samples(fbatch13, Type == "NegCon")
fbatch13_kit <- prune_taxa(taxa_sums(fbatch13_kit) > 0, fbatch13_kit)
fb13_control_vec <- as.vector(taxa_names(fbatch13_kit)) 
fb13_vec <- as.vector(taxa_names(fbatch13)) 
fb13_keep <- setdiff(fb13_vec, fb13_control_vec)
fb13_clean <- prune_taxa(fb13_keep, fbatch13)

# batch 14
fbatch14 = subset_samples(EX_ps, Fbatch == "14")  
fbatch14_kit = subset_samples(fbatch14, Type == "NegCon")
fbatch14_kit <- prune_taxa(taxa_sums(fbatch14_kit) > 0, fbatch14_kit)
fb14_control_vec <- as.vector(taxa_names(fbatch14_kit)) 
fb14_vec <- as.vector(taxa_names(fbatch14)) 
fb14_keep <- setdiff(fb14_vec, fb14_control_vec)
fb14_clean <- prune_taxa(fb14_keep, fbatch14)

# batch 15
fbatch15 = subset_samples(EX_ps, Fbatch == "15")  
fbatch15_kit = subset_samples(fbatch15, Type == "NegCon")
fbatch15_kit <- prune_taxa(taxa_sums(fbatch15_kit) > 0, fbatch15_kit)
fb15_control_vec <- as.vector(taxa_names(fbatch15_kit)) 
fb15_vec <- as.vector(taxa_names(fbatch15)) 
fb15_keep <- setdiff(fb15_vec, fb15_control_vec)
fb15_clean <- prune_taxa(fb15_keep, fbatch15)

# batch 0

fbatch0 = subset_samples(EX_ps, Fbatch == "0")  
fbatch0_kit = subset_samples(fbatch0, Type == "NegCon")
fbatch0_kit <- prune_taxa(taxa_sums(fbatch0_kit) > 0, fbatch0_kit)
fb0_control_vec <- as.vector(taxa_names(fbatch0_kit)) 
fb0_vec <- as.vector(taxa_names(fbatch0)) 
fb0_keep <- setdiff(fb0_vec, fb0_control_vec)
fb0_clean <- prune_taxa(fb0_keep, fbatch0)

```

```{r}
# Merge the phyloseq objects back together, then remove any blank taxa or samples
EX_ps_NC_batch_clean <- merge_phyloseq(fb0_clean, fb2_clean, fb3_clean, fb5_clean, fb6_clean, fb7_clean, fb8_clean, fb9_clean, fb11_clean, fb14_clean, fb15_clean) 

# Clean out taxa/SV columns that are no longer present
EX_ps_NC_batch_clean <- prune_taxa(taxa_sums(EX_ps_NC_batch_clean) > 0, EX_ps_NC_batch_clean) 

EX_ps_NC_batch_clean <- prune_samples(sample_sums(EX_ps_NC_batch_clean) > 0, EX_ps_NC_batch_clean)
EX_ps_NC_batch_clean
```


```{r recheck_ordination, echo = FALSE}
# Check simple ordination again to see if decontam worked

EX_cleaner.ord <- ordinate(EX_ps_NC_batch_clean, method ="PCoA", "jaccard", binary = TRUE) 
 
plot_ordination(EX_ps_NC_batch_clean, EX_cleaner.ord, type="samples", color="Fbatch", title="Prelim 12S Jaccard Binary Ordination Post-Decontam")
```


# Remove Unwanted Taxa with Dplyr


```{r remove_taxa, echo = FALSE}
EX_ps_clean <- EX_ps_NC_batch_clean %>% 
  subset_taxa(Kingdom != "Bacteria" & Genus != "Homo") 

```

```{r clean_columns, echo = FALSE}
EX_ps_clean <- prune_taxa(taxa_sums(EX_ps_clean) > 0, EX_ps_clean) 
EX_ps_clean <- prune_samples(sample_sums(EX_ps_clean) > 0, EX_ps_clean)

EX_ps_clean
saveRDS(EX_ps_clean, 'C:/Users/bydav/Desktop/12SPrelim_EX_ps_clean.RDS')
```

