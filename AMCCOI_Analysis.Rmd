---
title: "AMCCOI"
author: "BYDavis"
date: "2024-04-17"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Markdown file to analyze AMC water eDNA samples, sequenced using the BF2/BR2 COI primer

# Run set-up files
```{r COI_config, echo = FALSE}
# config file with paths and versioning
source("AMCCOI_config.R")
```
```{r COI_reload}
# File with previous outputs to make reloading easier
source("AMCCOI_reload.R")
```

# Set raw file types
```{r raw_isolate, echo = FALSE}

# Specify file name formats
fnsBF <- list.files(path_rawBF)
fastqsBF <- fnsBF[grepl('.gz$', fnsBF)]

fnsBR <- list.files(path_rawBR)
fastqsBR <- fnsBR[grepl('.gz$', fnsBR)]

# The file paths still include the desktop.ini file, so let's specify a file path to lead future code only to the fastq files in the folder

fnsBFisolate <- file.path(path_rawBF, fastqsBF)
fnsBRisolate <- file.path(path_rawBR, fastqsBR)

# Set sample names to a vector
# Remove path and the .gz extension
# Repeat file_path_sans_ext to also remove the .fastq
namesBFfast <- tools::file_path_sans_ext(basename(fastqsBF))
namesBF <- tools::file_path_sans_ext(namesBFfast)

namesBRfast <- tools::file_path_sans_ext(basename(fastqsBR))
# Repeat file_path_sans_ext to also remove the .fastq
namesBR <- tools::file_path_sans_ext(namesBRfast)
```


# Check Sequence Quality

Run 6 randomly selected quality profile plots per primer per read type (forward or reverse). Number will correspond to the file order.

```{r random_selection, echo = FALSE}
# Numbers for BF2 Forward reads:
sample(1:78, 6, replace = FALSE)
  # Results on 3/20/2024: 48 64 20 57 15 11

# Numbers for BF2 Reverse reads:
sample(1:78, 6, replace = FALSE)
  # Results on 3/20/2024: 15, 49, 56, 78, 11, 28
```

Now generate the randomly selected plots
```{r quality_profile, echo = FALSE}
# B Forward:
ggsave("BF2ForwardQuality_RNG48.png", plot = plotQualityProfile(fnsBFisolate[48]), path = path_outputs, width = 6, height = 4, units = "in")

ggsave("BF2ForwardQuality_RNG64.png", plot = plotQualityProfile(fnsBFisolate[64]), path = path_outputs, width = 6, height = 4, units = "in")

ggsave("BF2ForwardQuality_RNG20.png", plot = plotQualityProfile(fnsBFisolate[20]), path = path_outputs, width = 6, height = 4, units = "in")

ggsave("BF2ForwardQuality_RNG57.png", plot = plotQualityProfile(fnsBFisolate[57]), path = path_outputs, width = 6, height = 4, units = "in")

ggsave("BF2ForwardQuality_RNG15.png", plot = plotQualityProfile(fnsBFisolate[15]), path = path_outputs, width = 6, height = 4, units = "in")

ggsave("BF2ForwardQuality_RNG11.png", plot = plotQualityProfile(fnsBFisolate[11]), path = path_outputs, width = 6, height = 4, units = "in")

# Notify when the forward plots are done
beep(sound = "fanfare")

# B Reverse:
ggsave("BR2ReverseQuality_RNG15.png", plot = plotQualityProfile(fnsBRisolate[15]), path = path_outputs, width = 6, height = 4, units = "in")

ggsave("BR2ReverseQuality_RNG49.png", plot = plotQualityProfile(fnsBRisolate[49]), path = path_outputs, width = 6, height = 4, units = "in")

ggsave("BR2ReverseQuality_RNG56.png", plot = plotQualityProfile(fnsBRisolate[56]), path = path_outputs, width = 6, height = 4, units = "in")

ggsave("BR2ReverseQuality_RNG77.png", plot = plotQualityProfile(fnsBRisolate[77]), path = path_outputs, width = 6, height = 4, units = "in")

ggsave("BR2ReverseQuality_RNG11.png", plot = plotQualityProfile(fnsBRisolate[11]), path = path_outputs, width = 6, height = 4, units = "in")

ggsave("BR2ReverseQuality_RNG28.png", plot = plotQualityProfile(fnsBRisolate[28]), path = path_outputs, width = 6, height = 4, units = "in")

# Notify when the reverse plots are done
beep(sound = "fanfare")
```

The indexes and adapters have been removed from the sequence files, but the original primers are still attached. Need to account for their presence in the trim amounts and remove them.

BF2/BR2 COI Region: ~420 bp - this is longer than the cycle length, but should still provide 260bp of overlap

BF2 primer length: 20 -  GCHCCHGAYATRGCHTTYCC 

BR2 primer length: 20 -  TCDGGRTGNCCRAARAAYCA 


Given a desired score of 25+, trim reverse after 250 and forward after 280

# Begin filtering process
```{r filtAndTrim, echo = TRUE}
# Trimming parameters
filtoutB <- filterAndTrim(file.path(path_rawBF, fastqsBF), file.path(path_filtBF, paste0(namesBF, "filt.fastq.gz")), file.path(path_rawBR, fastqsBR), file.path(path_filtBR, paste0(namesBR, "filt.fastq.gz")), trimLeft = c(20,20), trimRight=c(20,50), maxN=0, maxEE=c(2,2), verbose=TRUE) 

# Save output
saveRDS(filtoutB, "G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/COIB/5-May03-2024/FiltOutput.rds")
```


# Explore filtered output 

```{r assess_filt, echo = FALSE}

# Order by filtered read amount
filtoutB[order(filtoutB[,2], decreasing=FALSE),]

# Compare total raw in and filtered out read amounts
colSums(filtoutB)

# Save output
write.csv(filtoutB, file.path(path_outputs, "FiltOutput.csv"))
```


# Look at filtered trends
```{r filter_trends, echo = FALSE}
# Plot read numbers before and after trimming
filttrendB <- ggplot(as.data.frame(filtoutB)) + geom_point(aes(row.names(filtoutB), reads.in), color = "blue") + geom_point(aes(row.names(filtoutB), reads.out), color = "orange") + ggtitle("Filter Trends for AMC BF2/BR2 Reads")

# View plot
filttrendB

# Save plot
ggsave("FilterTrends.png", plot = filttrendB, path = path_outputs, width = 6, height = 4, units = "in")
```


# Error Rates and Dereplication

First we need to set a seed and make sure the paths are all still set.
```{r error_setup, echo = FALSE}
# Set seed
set.seed(0743)

# BForward
# create a list of files in the path
filtnamesBFinter <- list.files(path_filtBF, full.names = TRUE)

# Specify I only want the files with the .gz extension
filtnamesBF <- filtnamesBFinter[grepl('.gz$', filtnamesBFinter)]

# Extract just the file name, not the path, and remove the .gz extension. This leaves on the .fastq extension
fastqfiltBF <- tools::file_path_sans_ext(basename(filtnamesBF))

# Remove the .fastq extension
namesBFfilt <- tools::file_path_sans_ext(basename(fastqfiltBF))

# Repeat for reverse
filtnamesBRinter <- list.files(path_filtBR, full.names = TRUE)
filtnamesBR <- filtnamesBRinter[grepl('.gz$', filtnamesBRinter)]
fastqfiltBR <- tools::file_path_sans_ext(basename(filtnamesBR))
namesBRfilt <- tools::file_path_sans_ext(basename(fastqfiltBR))
```


## Dereplication

This step comes from the dada2 workflow (https://bioconductor.org/packages/devel/bioc/vignettes/dada2/inst/doc/dada2-intro.html#learn-the-error-rates)

```{r derep, echo = FALSE}
derepBF <- derepFastq(filtnamesBF, verbose = TRUE)
derepBR <- derepFastq(filtnamesBR, verbose = TRUE)
```

Now that the names are set up, we can run the simulations to learn and estimate the number of errors in each filtered folder. This step is in Sue's code (and is the source of the saveRDS and plotErrors lines), but using the default parameters from the dada2 workflow


## Error Rates

```{r error_rates, echo = FALSE}
# Forward error rates
errBF <- learnErrors(derepBF, multithread = FALSE, randomize = TRUE)

# Save error rates
saveRDS(errBF, "G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/COIB/5-May03-2024/ForwardError.rds")

# Generate and save forward error plot
ggsave("Forward_ErrorPlot.png", path = path_outputs, plotErrors(errBF, nominalQ = TRUE), width = 6, height = 4, units = "in") 

# Reverse error rates
errBR <- learnErrors(derepBR, multithread = FALSE, randomize = TRUE)

# Save error rates
saveRDS(errBR, "G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/COIB/5-May03-2024/ReverseError.rds")

# Generate and save reverse error plot
ggsave("Reverse_ErrorPlot.png", path = path_outputs, plotErrors(errBR, nominalQ = TRUE), width = 6, height = 4, units = "in") 

# This takes a long time. If you have to do it again, include this:
beep(sound = "fanfare")
```


# Infer sample composition
```{r sample_composition, echo = FALSE}
dadaBF <- dada(derepBF, err = errBF, multithread = FALSE)
print("dada BF finished")
beep(sound = "coin")

dadaBR <- dada(derepBR, err = errBR, multithread = FALSE)
print("dada BR finished")
beep(sound = "fanfare")

# Save all in case I need to reload the dada objects
saveRDS(dadaBF, "G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/COIB/5-May03-2024/BForward_SampleComp.rds")
saveRDS(dadaBR, "G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/COIB/5-May03-2024/BReverse_SampleComp.rds")
```


## Merge paired reads

```{r merge_reads, echo = FALSE}
mergersB <- mergePairs(dadaBF, derepBF, dadaBR, derepBR, verbose = TRUE)

# Save output
saveRDS(mergersB, "G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/COIB/5-May03-2024/BMergedSampleComp.rds")
```

```{r seqtab, echo = FALSE}
# Turn into sequence table
seqtabB <- makeSequenceTable(mergersB)

# Save output
saveRDS(seqtabB, "G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/COIB/5-May03-2024/BMerged Sequence Table.rds")
```

# Remove Chimeras 
```{r no_chim, echo = FALSE}
# Remove chimeras
seqtabB.nochim <- removeBimeraDenovo(seqtabB, method = "consensus", multithread = FALSE, verbose = TRUE)

# Save
saveRDS(seqtabB.nochim, "G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/COIB/5-May03-2024/BMerged Sequence No Chimera Table.rds")

# Notification
beep(sound = "coin")
```


# Workflow Verification

```{r workflow_verification, echo = FALSE}
# Function for sum
getN <- function(x) sum(getUniques(x))

# Combine read numbers across workflow stages into a table
trackB <- cbind(filtoutB, sapply(dadaBF, getN), sapply(dadaBR, getN), sapply(mergersB, getN), rowSums(seqtabB.nochim))

# Set column names
colnames(trackB) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim")

# Save output
write.csv(trackB, file.path(path_outputs, "WorkflowVerification.csv"))
```


# Assign Taxonomy

```{r assign_taxonomy, echo = FALSE}
# Very slow and intensive
all.taxa <- assignTaxonomy(seqtabB.nochim, 'C:/Users/bydav/Desktop/RefDB_Dev/output/3-May19-2024/COI_REFDB.fasta', tryRC = TRUE, verbose = TRUE)
beep(sound = "fanfare")

write.csv(all.taxa, file.path(path_outputs, "COIAMC_AssignedTaxa.csv"))
```


# Prep for Phyloseq

First we need to update the row names for the seqtab12.nochim, all.taxa, and meta objects before attempting to make the phyloseq object. Since at least one sample was dropped during processing, we have to read meta in without row.names, remove the row(s) associated with the dropped sample(s), then reset the sampleID column to row.names
```{r name_check, include = FALSE}
# Update the all.taxa row names to be the actual sequences
all.taxa <- data.frame(all.taxa, row.names = 1)

# Order seqtab.nochim by row names
seqtabB.nochim <- seqtabB.nochim[order(row.names(seqtabB.nochim)), ]

# Order the meta file by sample name
meta <- meta[order(sample(meta)), ]
# Remove the row(s) associated with dropped sample(s) from the meta spreadsheet - the only way I can do this is one row at a time
meta2 <- subset(meta, sample != "AMC22_AB01")
meta2 <- subset(meta2, sample != "AMC23_AB04") 
meta2 <- subset(meta2, sample != "AMC23_MB09") 

# Set the sample column as row.names
meta <- data.frame(meta2, row.names = 1)
# Order the meta file by row.names
meta <- meta[order(row.names(meta)), ]

# Make sure all samples in seqtab.nochim match and are in the same order as in meta, because the next step is a flat replacement of row.names
row.names(seqtabB.nochim) <- row.names(meta)
```


# Create the Phyloseq object
```{r ps_object, echo = FALSE}
# Create phyloseq object with all samples
EX_ps <- phyloseq(otu_table(seqtabB.nochim, taxa_are_rows=FALSE), sample_data(meta), tax_table(as.matrix(all.taxa)))

# SAVE 
saveRDS(EX_ps, "G:/My Drive/2_UMaine FSM - Field Projects/AMC/Data/dataoutputs/COIB/5-May03-2024/InitialPhyloseq.rds")
```


# Exploratory richness plots
```{r initial_exploratory}
# I'd like to make a stacked bar plot, before any taxa-filtering, of the read abundances
# Set function to make a proportional graph
EX_ps.func <- transform_sample_counts(EX_ps, function(x) x / sum(x) )
# Plot based on Phylum
plot_bar(EX_ps.func, fill="Phylum") + ggtitle("Proportion by Phylum of Identified Reads - COI")
  # Warning: Removed 79588 rows containing missing values or values outside the scale range (`geom_bar()`). 

# Save plot
ggsave("PreDecontam_IDProportions.png", path = path_outputs, plot_bar(EX_ps.func, fill="Phylum") + ggtitle("Proportion by Phylum of Identified Reads"), width = 7, height = 4, units = "in") 
```

### NTS: May need to repeat ^ plot, sample IDs are illegible


### All prior clean


# Decontam with Negative Controls (Ishaq Method)
Clean all batches and then merge together into a clean phyloseq object - make this into a loop after MSWC
```{r}
# batch 3
fbatch3 = subset_samples(EX_ps, Fbatch == "3")  
fbatch3_kit = subset_samples(fbatch3, Type == "NegCon")
fbatch3_kit <- prune_taxa(taxa_sums(fbatch3_kit) > 0, fbatch3_kit)
fb3_control_vec <- as.vector(taxa_names(fbatch3_kit)) 
fb3_vec <- as.vector(taxa_names(fbatch3)) 
fb3_keep <- setdiff(fb3_vec, fb3_control_vec)
fb3_clean <- prune_taxa(fb3_keep, fbatch3)

# batch 4
#fbatch4 = subset_samples(EX_ps, Fbatch == "4")  
#fbatch4_kit = subset_samples(fbatch4, Type == "NegCon")
#fbatch4_kit <- prune_taxa(taxa_sums(fbatch4_kit) > 0, fbatch4_kit)
#fb4_control_vec <- as.vector(taxa_names(fbatch4_kit)) 
#fb4_vec <- as.vector(taxa_names(fbatch4)) 
#fb4_keep <- setdiff(fb4_vec, fb4_control_vec)
#fb4_clean <- prune_taxa(fb4_keep, fbatch4)

# batch 5
fbatch5 = subset_samples(EX_ps, Fbatch == "5")  
fbatch5_kit = subset_samples(fbatch5, Type == "NegCon")
fbatch5_kit <- prune_taxa(taxa_sums(fbatch5_kit) > 0, fbatch5_kit)
fb5_control_vec <- as.vector(taxa_names(fbatch5_kit)) 
fb5_vec <- as.vector(taxa_names(fbatch5)) 
fb5_keep <- setdiff(fb5_vec, fb5_control_vec)
fb5_clean <- prune_taxa(fb5_keep, fbatch5)

# batch 6
fbatch6 = subset_samples(EX_ps, Fbatch == "6")  
fbatch6_kit = subset_samples(fbatch6, Type == "NegCon")
fbatch6_kit <- prune_taxa(taxa_sums(fbatch6_kit) > 0, fbatch6_kit)
fb6_control_vec <- as.vector(taxa_names(fbatch6_kit)) 
fb6_vec <- as.vector(taxa_names(fbatch6)) 
fb6_keep <- setdiff(fb6_vec, fb6_control_vec)
fb6_clean <- prune_taxa(fb6_keep, fbatch6)

# batch 7
fbatch7 = subset_samples(EX_ps, Fbatch == "7")  
fbatch7_kit = subset_samples(fbatch7, Type == "NegCon")
fbatch7_kit <- prune_taxa(taxa_sums(fbatch7_kit) > 0, fbatch7_kit)
fb7_control_vec <- as.vector(taxa_names(fbatch7_kit)) 
fb7_vec <- as.vector(taxa_names(fbatch7)) 
fb7_keep <- setdiff(fb7_vec, fb7_control_vec)
fb7_clean <- prune_taxa(fb7_keep, fbatch7)

# batch 8
fbatch8 = subset_samples(EX_ps, Fbatch == "8")  
fbatch8_kit = subset_samples(fbatch8, Type == "NegCon")
fbatch8_kit <- prune_taxa(taxa_sums(fbatch8_kit) > 0, fbatch8_kit)
fb8_control_vec <- as.vector(taxa_names(fbatch8_kit)) 
fb8_vec <- as.vector(taxa_names(fbatch8)) 
fb8_keep <- setdiff(fb8_vec, fb8_control_vec)
fb8_clean <- prune_taxa(fb8_keep, fbatch8)

# batch 9
fbatch9 = subset_samples(EX_ps, Fbatch == "9")  
fbatch9_kit = subset_samples(fbatch9, Type == "NegCon")
fbatch9_kit <- prune_taxa(taxa_sums(fbatch9_kit) > 0, fbatch9_kit)
fb9_control_vec <- as.vector(taxa_names(fbatch9_kit)) 
fb9_vec <- as.vector(taxa_names(fbatch9)) 
fb9_keep <- setdiff(fb9_vec, fb9_control_vec)
fb9_clean <- prune_taxa(fb9_keep, fbatch9)

# batch 10
fbatch10 = subset_samples(EX_ps, Fbatch == "10")  
fbatch10_kit = subset_samples(fbatch10, Type == "NegCon")
fbatch10_kit <- prune_taxa(taxa_sums(fbatch10_kit) > 0, fbatch10_kit)
fb10_control_vec <- as.vector(taxa_names(fbatch10_kit)) 
fb10_vec <- as.vector(taxa_names(fbatch10)) 
fb10_keep <- setdiff(fb10_vec, fb10_control_vec)
fb10_clean <- prune_taxa(fb10_keep, fbatch10)

# batch 11
fbatch11 = subset_samples(EX_ps, Fbatch == "11")  
fbatch11_kit = subset_samples(fbatch11, Type == "NegCon")
fbatch11_kit <- prune_taxa(taxa_sums(fbatch11_kit) > 0, fbatch11_kit)
fb11_control_vec <- as.vector(taxa_names(fbatch11_kit)) 
fb11_vec <- as.vector(taxa_names(fbatch11)) 
fb11_keep <- setdiff(fb11_vec, fb11_control_vec)
fb11_clean <- prune_taxa(fb11_keep, fbatch11)

# batch 12
#fbatch12 = subset_samples(EX_ps, Fbatch == "12")  
#fbatch12_kit = subset_samples(fbatch12, Type == "NegCon")
#fbatch12_kit <- prune_taxa(taxa_sums(fbatch12_kit) > 0, fbatch12_kit)
#fb12_control_vec <- as.vector(taxa_names(fbatch12_kit)) 
#fb12_vec <- as.vector(taxa_names(fbatch12)) 
#fb12_keep <- setdiff(fb12_vec, fb12_control_vec)
#fb12_clean <- prune_taxa(fb12_keep, fbatch12)

# batch 13
fbatch13 = subset_samples(EX_ps, Fbatch == "13")  
fbatch13_kit = subset_samples(fbatch13, Type == "NegCon")
fbatch13_kit <- prune_taxa(taxa_sums(fbatch13_kit) > 0, fbatch13_kit)
fb13_control_vec <- as.vector(taxa_names(fbatch13_kit)) 
fb13_vec <- as.vector(taxa_names(fbatch13)) 
fb13_keep <- setdiff(fb13_vec, fb13_control_vec)
fb13_clean <- prune_taxa(fb13_keep, fbatch13)

# batch 14
fbatch14 = subset_samples(EX_ps, Fbatch == "14")  
fbatch14_kit = subset_samples(fbatch14, Type == "NegCon")
fbatch14_kit <- prune_taxa(taxa_sums(fbatch14_kit) > 0, fbatch14_kit)
fb14_control_vec <- as.vector(taxa_names(fbatch14_kit)) 
fb14_vec <- as.vector(taxa_names(fbatch14)) 
fb14_keep <- setdiff(fb14_vec, fb14_control_vec)
fb14_clean <- prune_taxa(fb14_keep, fbatch14)

# batch 15
fbatch15 = subset_samples(EX_ps, Fbatch == "15")  
fbatch15_kit = subset_samples(fbatch15, Type == "NegCon")
fbatch15_kit <- prune_taxa(taxa_sums(fbatch15_kit) > 0, fbatch15_kit)
fb15_control_vec <- as.vector(taxa_names(fbatch15_kit)) 
fb15_vec <- as.vector(taxa_names(fbatch15)) 
fb15_keep <- setdiff(fb15_vec, fb15_control_vec)
fb15_clean <- prune_taxa(fb15_keep, fbatch15)

# batch 0

fbatch0 = subset_samples(EX_ps, Fbatch == "0")  
fbatch0_kit = subset_samples(fbatch0, Type == "NegCon")
fbatch0_kit <- prune_taxa(taxa_sums(fbatch0_kit) > 0, fbatch0_kit)
fb0_control_vec <- as.vector(taxa_names(fbatch0_kit)) 
fb0_vec <- as.vector(taxa_names(fbatch0)) 
fb0_keep <- setdiff(fb0_vec, fb0_control_vec)
fb0_clean <- prune_taxa(fb0_keep, fbatch0)

```

```{r}
# Merge the phyloseq objects back together, then remove any blank taxa or samples
EX_ps_NC_batch_clean <- merge_phyloseq(fb0_clean, fb2_clean, fb3_clean, fb5_clean, fb6_clean, fb7_clean, fb8_clean, fb9_clean, fb11_clean, fb14_clean, fb15_clean) 

# Clean out taxa/SV columns that are no longer present
EX_ps_NC_batch_clean <- prune_taxa(taxa_sums(EX_ps_NC_batch_clean) > 0, EX_ps_NC_batch_clean) 

EX_ps_NC_batch_clean <- prune_samples(sample_sums(EX_ps_NC_batch_clean) > 0, EX_ps_NC_batch_clean)
EX_ps_NC_batch_clean
```


```{r recheck_ordination, echo = FALSE}
# Check simple ordination again to see if decontam worked

EX_cleaner.ord <- ordinate(EX_ps_NC_batch_clean, method ="PCoA", "jaccard", binary = TRUE) 
 
plot_ordination(EX_ps_NC_batch_clean, EX_cleaner.ord, type="samples", color="Fbatch", title="Prelim 12S Jaccard Binary Ordination Post-Decontam")
```


# Remove Unwanted Taxa with Dplyr


```{r remove_taxa, echo = FALSE}
EX_ps_clean <- EX_ps_NC_batch_clean %>% 
  subset_taxa(Kingdom != "Bacteria" & Genus != "Homo") 

```

```{r clean_columns, echo = FALSE}
EX_ps_clean <- prune_taxa(taxa_sums(EX_ps_clean) > 0, EX_ps_clean) 
EX_ps_clean <- prune_samples(sample_sums(EX_ps_clean) > 0, EX_ps_clean)

EX_ps_clean
saveRDS(EX_ps_clean, 'C:/Users/bydav/Desktop/12SPrelim_EX_ps_clean.RDS')
```

